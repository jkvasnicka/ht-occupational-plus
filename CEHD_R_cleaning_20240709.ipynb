{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0199a-357a-4b25-b887-fa029698bf81",
   "metadata": {},
   "outputs": [],
   "source": [
    ".libPaths(\"C:/Users/phisar/Documents/Revolution/R/win-library/3.5\")\n",
    "setwd(\"C:\\\\Users\\\\phisar\\\\Dropbox (IRSST)\\\\PhD\\\\Projet IMIS\\\\Rï¿½sultats\\\\IMIS_ND_predict\\\\CEHD 84_18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a29e0265-00cc-4c5a-b2f5-10eaee050179",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>askpass</dt>\n",
       "\t\t<dd>'askpass'</dd>\n",
       "\t<dt>assertthat</dt>\n",
       "\t\t<dd>'assertthat'</dd>\n",
       "\t<dt>backports</dt>\n",
       "\t\t<dd>'backports'</dd>\n",
       "\t<dt>base</dt>\n",
       "\t\t<dd>'base'</dd>\n",
       "\t<dt>base64enc</dt>\n",
       "\t\t<dd>'base64enc'</dd>\n",
       "\t<dt>BH</dt>\n",
       "\t\t<dd>'BH'</dd>\n",
       "\t<dt>boot</dt>\n",
       "\t\t<dd>'boot'</dd>\n",
       "\t<dt>broom</dt>\n",
       "\t\t<dd>'broom'</dd>\n",
       "\t<dt>callr</dt>\n",
       "\t\t<dd>'callr'</dd>\n",
       "\t<dt>caret</dt>\n",
       "\t\t<dd>'caret'</dd>\n",
       "\t<dt>cellranger</dt>\n",
       "\t\t<dd>'cellranger'</dd>\n",
       "\t<dt>class</dt>\n",
       "\t\t<dd>'class'</dd>\n",
       "\t<dt>cli</dt>\n",
       "\t\t<dd>'cli'</dd>\n",
       "\t<dt>clipr</dt>\n",
       "\t\t<dd>'clipr'</dd>\n",
       "\t<dt>cluster</dt>\n",
       "\t\t<dd>'cluster'</dd>\n",
       "\t<dt>codetools</dt>\n",
       "\t\t<dd>'codetools'</dd>\n",
       "\t<dt>colorspace</dt>\n",
       "\t\t<dd>'colorspace'</dd>\n",
       "\t<dt>compiler</dt>\n",
       "\t\t<dd>'compiler'</dd>\n",
       "\t<dt>crayon</dt>\n",
       "\t\t<dd>'crayon'</dd>\n",
       "\t<dt>curl</dt>\n",
       "\t\t<dd>'curl'</dd>\n",
       "\t<dt>data.table</dt>\n",
       "\t\t<dd>'data.table'</dd>\n",
       "\t<dt>datasets</dt>\n",
       "\t\t<dd>'datasets'</dd>\n",
       "\t<dt>DBI</dt>\n",
       "\t\t<dd>'DBI'</dd>\n",
       "\t<dt>dbplyr</dt>\n",
       "\t\t<dd>'dbplyr'</dd>\n",
       "\t<dt>dichromat</dt>\n",
       "\t\t<dd>'dichromat'</dd>\n",
       "\t<dt>digest</dt>\n",
       "\t\t<dd>'digest'</dd>\n",
       "\t<dt>dplyr</dt>\n",
       "\t\t<dd>'dplyr'</dd>\n",
       "\t<dt>ellipsis</dt>\n",
       "\t\t<dd>'ellipsis'</dd>\n",
       "\t<dt>evaluate</dt>\n",
       "\t\t<dd>'evaluate'</dd>\n",
       "\t<dt>fansi</dt>\n",
       "\t\t<dd>'fansi'</dd>\n",
       "\t<dt>forcats</dt>\n",
       "\t\t<dd>'forcats'</dd>\n",
       "\t<dt>foreach</dt>\n",
       "\t\t<dd>'foreach'</dd>\n",
       "\t<dt>foreign</dt>\n",
       "\t\t<dd>'foreign'</dd>\n",
       "\t<dt>formatR</dt>\n",
       "\t\t<dd>'formatR'</dd>\n",
       "\t<dt>fs</dt>\n",
       "\t\t<dd>'fs'</dd>\n",
       "\t<dt>generics</dt>\n",
       "\t\t<dd>'generics'</dd>\n",
       "\t<dt>ggplot2</dt>\n",
       "\t\t<dd>'ggplot2'</dd>\n",
       "\t<dt>glmnet</dt>\n",
       "\t\t<dd>'glmnet'</dd>\n",
       "\t<dt>glue</dt>\n",
       "\t\t<dd>'glue'</dd>\n",
       "\t<dt>gower</dt>\n",
       "\t\t<dd>'gower'</dd>\n",
       "\t<dt>graphics</dt>\n",
       "\t\t<dd>'graphics'</dd>\n",
       "\t<dt>grDevices</dt>\n",
       "\t\t<dd>'grDevices'</dd>\n",
       "\t<dt>grid</dt>\n",
       "\t\t<dd>'grid'</dd>\n",
       "\t<dt>gtable</dt>\n",
       "\t\t<dd>'gtable'</dd>\n",
       "\t<dt>haven</dt>\n",
       "\t\t<dd>'haven'</dd>\n",
       "\t<dt>hexbin</dt>\n",
       "\t\t<dd>'hexbin'</dd>\n",
       "\t<dt>highr</dt>\n",
       "\t\t<dd>'highr'</dd>\n",
       "\t<dt>hms</dt>\n",
       "\t\t<dd>'hms'</dd>\n",
       "\t<dt>htmltools</dt>\n",
       "\t\t<dd>'htmltools'</dd>\n",
       "\t<dt>htmlwidgets</dt>\n",
       "\t\t<dd>'htmlwidgets'</dd>\n",
       "\t<dt>httpuv</dt>\n",
       "\t\t<dd>'httpuv'</dd>\n",
       "\t<dt>httr</dt>\n",
       "\t\t<dd>'httr'</dd>\n",
       "\t<dt>ipred</dt>\n",
       "\t\t<dd>'ipred'</dd>\n",
       "\t<dt>IRdisplay</dt>\n",
       "\t\t<dd>'IRdisplay'</dd>\n",
       "\t<dt>IRkernel</dt>\n",
       "\t\t<dd>'IRkernel'</dd>\n",
       "\t<dt>iterators</dt>\n",
       "\t\t<dd>'iterators'</dd>\n",
       "\t<dt>jsonlite</dt>\n",
       "\t\t<dd>'jsonlite'</dd>\n",
       "\t<dt>KernSmooth</dt>\n",
       "\t\t<dd>'KernSmooth'</dd>\n",
       "\t<dt>knitr</dt>\n",
       "\t\t<dd>'knitr'</dd>\n",
       "\t<dt>labeling</dt>\n",
       "\t\t<dd>'labeling'</dd>\n",
       "\t<dt>later</dt>\n",
       "\t\t<dd>'later'</dd>\n",
       "\t<dt>lattice</dt>\n",
       "\t\t<dd>'lattice'</dd>\n",
       "\t<dt>lava</dt>\n",
       "\t\t<dd>'lava'</dd>\n",
       "\t<dt>lazyeval</dt>\n",
       "\t\t<dd>'lazyeval'</dd>\n",
       "\t<dt>lubridate</dt>\n",
       "\t\t<dd>'lubridate'</dd>\n",
       "\t<dt>magrittr</dt>\n",
       "\t\t<dd>'magrittr'</dd>\n",
       "\t<dt>maps</dt>\n",
       "\t\t<dd>'maps'</dd>\n",
       "\t<dt>markdown</dt>\n",
       "\t\t<dd>'markdown'</dd>\n",
       "\t<dt>MASS</dt>\n",
       "\t\t<dd>'MASS'</dd>\n",
       "\t<dt>Matrix</dt>\n",
       "\t\t<dd>'Matrix'</dd>\n",
       "\t<dt>methods</dt>\n",
       "\t\t<dd>'methods'</dd>\n",
       "\t<dt>mgcv</dt>\n",
       "\t\t<dd>'mgcv'</dd>\n",
       "\t<dt>mime</dt>\n",
       "\t\t<dd>'mime'</dd>\n",
       "\t<dt>ModelMetrics</dt>\n",
       "\t\t<dd>'ModelMetrics'</dd>\n",
       "\t<dt>modelr</dt>\n",
       "\t\t<dd>'modelr'</dd>\n",
       "\t<dt>munsell</dt>\n",
       "\t\t<dd>'munsell'</dd>\n",
       "\t<dt>nlme</dt>\n",
       "\t\t<dd>'nlme'</dd>\n",
       "\t<dt>nnet</dt>\n",
       "\t\t<dd>'nnet'</dd>\n",
       "\t<dt>numDeriv</dt>\n",
       "\t\t<dd>'numDeriv'</dd>\n",
       "\t<dt>openssl</dt>\n",
       "\t\t<dd>'openssl'</dd>\n",
       "\t<dt>parallel</dt>\n",
       "\t\t<dd>'parallel'</dd>\n",
       "\t<dt>pbdZMQ</dt>\n",
       "\t\t<dd>'pbdZMQ'</dd>\n",
       "\t<dt>pillar</dt>\n",
       "\t\t<dd>'pillar'</dd>\n",
       "\t<dt>pkgconfig</dt>\n",
       "\t\t<dd>'pkgconfig'</dd>\n",
       "\t<dt>plogr</dt>\n",
       "\t\t<dd>'plogr'</dd>\n",
       "\t<dt>plyr</dt>\n",
       "\t\t<dd>'plyr'</dd>\n",
       "\t<dt>prettyunits</dt>\n",
       "\t\t<dd>'prettyunits'</dd>\n",
       "\t<dt>processx</dt>\n",
       "\t\t<dd>'processx'</dd>\n",
       "\t<dt>prodlim</dt>\n",
       "\t\t<dd>'prodlim'</dd>\n",
       "\t<dt>progress</dt>\n",
       "\t\t<dd>'progress'</dd>\n",
       "\t<dt>promises</dt>\n",
       "\t\t<dd>'promises'</dd>\n",
       "\t<dt>ps</dt>\n",
       "\t\t<dd>'ps'</dd>\n",
       "\t<dt>purrr</dt>\n",
       "\t\t<dd>'purrr'</dd>\n",
       "\t<dt>quantmod</dt>\n",
       "\t\t<dd>'quantmod'</dd>\n",
       "\t<dt>R6</dt>\n",
       "\t\t<dd>'R6'</dd>\n",
       "\t<dt>randomForest</dt>\n",
       "\t\t<dd>'randomForest'</dd>\n",
       "\t<dt>rbokeh</dt>\n",
       "\t\t<dd>'rbokeh'</dd>\n",
       "\t<dt>RColorBrewer</dt>\n",
       "\t\t<dd>'RColorBrewer'</dd>\n",
       "\t<dt>Rcpp</dt>\n",
       "\t\t<dd>'Rcpp'</dd>\n",
       "\t<dt>RcppRoll</dt>\n",
       "\t\t<dd>'RcppRoll'</dd>\n",
       "\t<dt>readr</dt>\n",
       "\t\t<dd>'readr'</dd>\n",
       "\t<dt>readxl</dt>\n",
       "\t\t<dd>'readxl'</dd>\n",
       "\t<dt>recipes</dt>\n",
       "\t\t<dd>'recipes'</dd>\n",
       "\t<dt>rematch</dt>\n",
       "\t\t<dd>'rematch'</dd>\n",
       "\t<dt>repr</dt>\n",
       "\t\t<dd>'repr'</dd>\n",
       "\t<dt>reprex</dt>\n",
       "\t\t<dd>'reprex'</dd>\n",
       "\t<dt>reshape2</dt>\n",
       "\t\t<dd>'reshape2'</dd>\n",
       "\t<dt>rlang</dt>\n",
       "\t\t<dd>'rlang'</dd>\n",
       "\t<dt>rmarkdown</dt>\n",
       "\t\t<dd>'rmarkdown'</dd>\n",
       "\t<dt>rpart</dt>\n",
       "\t\t<dd>'rpart'</dd>\n",
       "\t<dt>rstudioapi</dt>\n",
       "\t\t<dd>'rstudioapi'</dd>\n",
       "\t<dt>rvest</dt>\n",
       "\t\t<dd>'rvest'</dd>\n",
       "\t<dt>scales</dt>\n",
       "\t\t<dd>'scales'</dd>\n",
       "\t<dt>selectr</dt>\n",
       "\t\t<dd>'selectr'</dd>\n",
       "\t<dt>shiny</dt>\n",
       "\t\t<dd>'shiny'</dd>\n",
       "\t<dt>sourcetools</dt>\n",
       "\t\t<dd>'sourcetools'</dd>\n",
       "\t<dt>spatial</dt>\n",
       "\t\t<dd>'spatial'</dd>\n",
       "\t<dt>splines</dt>\n",
       "\t\t<dd>'splines'</dd>\n",
       "\t<dt>SQUAREM</dt>\n",
       "\t\t<dd>'SQUAREM'</dd>\n",
       "\t<dt>stats</dt>\n",
       "\t\t<dd>'stats'</dd>\n",
       "\t<dt>stats4</dt>\n",
       "\t\t<dd>'stats4'</dd>\n",
       "\t<dt>stringi</dt>\n",
       "\t\t<dd>'stringi'</dd>\n",
       "\t<dt>stringr</dt>\n",
       "\t\t<dd>'stringr'</dd>\n",
       "\t<dt>survival</dt>\n",
       "\t\t<dd>'survival'</dd>\n",
       "\t<dt>sys</dt>\n",
       "\t\t<dd>'sys'</dd>\n",
       "\t<dt>tcltk</dt>\n",
       "\t\t<dd>'tcltk'</dd>\n",
       "\t<dt>tibble</dt>\n",
       "\t\t<dd>'tibble'</dd>\n",
       "\t<dt>tidyr</dt>\n",
       "\t\t<dd>'tidyr'</dd>\n",
       "\t<dt>tidyselect</dt>\n",
       "\t\t<dd>'tidyselect'</dd>\n",
       "\t<dt>tidyverse</dt>\n",
       "\t\t<dd>'tidyverse'</dd>\n",
       "\t<dt>timeDate</dt>\n",
       "\t\t<dd>'timeDate'</dd>\n",
       "\t<dt>tinytex</dt>\n",
       "\t\t<dd>'tinytex'</dd>\n",
       "\t<dt>tools</dt>\n",
       "\t\t<dd>'tools'</dd>\n",
       "\t<dt>translations</dt>\n",
       "\t\t<dd>'translations'</dd>\n",
       "\t<dt>TTR</dt>\n",
       "\t\t<dd>'TTR'</dd>\n",
       "\t<dt>utf8</dt>\n",
       "\t\t<dd>'utf8'</dd>\n",
       "\t<dt>utils</dt>\n",
       "\t\t<dd>'utils'</dd>\n",
       "\t<dt>uuid</dt>\n",
       "\t\t<dd>'uuid'</dd>\n",
       "\t<dt>viridisLite</dt>\n",
       "\t\t<dd>'viridisLite'</dd>\n",
       "\t<dt>whisker</dt>\n",
       "\t\t<dd>'whisker'</dd>\n",
       "\t<dt>withr</dt>\n",
       "\t\t<dd>'withr'</dd>\n",
       "\t<dt>xfun</dt>\n",
       "\t\t<dd>'xfun'</dd>\n",
       "\t<dt>xml2</dt>\n",
       "\t\t<dd>'xml2'</dd>\n",
       "\t<dt>xtable</dt>\n",
       "\t\t<dd>'xtable'</dd>\n",
       "\t<dt>xts</dt>\n",
       "\t\t<dd>'xts'</dd>\n",
       "\t<dt>yaml</dt>\n",
       "\t\t<dd>'yaml'</dd>\n",
       "\t<dt>zoo</dt>\n",
       "\t\t<dd>'zoo'</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[askpass] 'askpass'\n",
       "\\item[assertthat] 'assertthat'\n",
       "\\item[backports] 'backports'\n",
       "\\item[base] 'base'\n",
       "\\item[base64enc] 'base64enc'\n",
       "\\item[BH] 'BH'\n",
       "\\item[boot] 'boot'\n",
       "\\item[broom] 'broom'\n",
       "\\item[callr] 'callr'\n",
       "\\item[caret] 'caret'\n",
       "\\item[cellranger] 'cellranger'\n",
       "\\item[class] 'class'\n",
       "\\item[cli] 'cli'\n",
       "\\item[clipr] 'clipr'\n",
       "\\item[cluster] 'cluster'\n",
       "\\item[codetools] 'codetools'\n",
       "\\item[colorspace] 'colorspace'\n",
       "\\item[compiler] 'compiler'\n",
       "\\item[crayon] 'crayon'\n",
       "\\item[curl] 'curl'\n",
       "\\item[data.table] 'data.table'\n",
       "\\item[datasets] 'datasets'\n",
       "\\item[DBI] 'DBI'\n",
       "\\item[dbplyr] 'dbplyr'\n",
       "\\item[dichromat] 'dichromat'\n",
       "\\item[digest] 'digest'\n",
       "\\item[dplyr] 'dplyr'\n",
       "\\item[ellipsis] 'ellipsis'\n",
       "\\item[evaluate] 'evaluate'\n",
       "\\item[fansi] 'fansi'\n",
       "\\item[forcats] 'forcats'\n",
       "\\item[foreach] 'foreach'\n",
       "\\item[foreign] 'foreign'\n",
       "\\item[formatR] 'formatR'\n",
       "\\item[fs] 'fs'\n",
       "\\item[generics] 'generics'\n",
       "\\item[ggplot2] 'ggplot2'\n",
       "\\item[glmnet] 'glmnet'\n",
       "\\item[glue] 'glue'\n",
       "\\item[gower] 'gower'\n",
       "\\item[graphics] 'graphics'\n",
       "\\item[grDevices] 'grDevices'\n",
       "\\item[grid] 'grid'\n",
       "\\item[gtable] 'gtable'\n",
       "\\item[haven] 'haven'\n",
       "\\item[hexbin] 'hexbin'\n",
       "\\item[highr] 'highr'\n",
       "\\item[hms] 'hms'\n",
       "\\item[htmltools] 'htmltools'\n",
       "\\item[htmlwidgets] 'htmlwidgets'\n",
       "\\item[httpuv] 'httpuv'\n",
       "\\item[httr] 'httr'\n",
       "\\item[ipred] 'ipred'\n",
       "\\item[IRdisplay] 'IRdisplay'\n",
       "\\item[IRkernel] 'IRkernel'\n",
       "\\item[iterators] 'iterators'\n",
       "\\item[jsonlite] 'jsonlite'\n",
       "\\item[KernSmooth] 'KernSmooth'\n",
       "\\item[knitr] 'knitr'\n",
       "\\item[labeling] 'labeling'\n",
       "\\item[later] 'later'\n",
       "\\item[lattice] 'lattice'\n",
       "\\item[lava] 'lava'\n",
       "\\item[lazyeval] 'lazyeval'\n",
       "\\item[lubridate] 'lubridate'\n",
       "\\item[magrittr] 'magrittr'\n",
       "\\item[maps] 'maps'\n",
       "\\item[markdown] 'markdown'\n",
       "\\item[MASS] 'MASS'\n",
       "\\item[Matrix] 'Matrix'\n",
       "\\item[methods] 'methods'\n",
       "\\item[mgcv] 'mgcv'\n",
       "\\item[mime] 'mime'\n",
       "\\item[ModelMetrics] 'ModelMetrics'\n",
       "\\item[modelr] 'modelr'\n",
       "\\item[munsell] 'munsell'\n",
       "\\item[nlme] 'nlme'\n",
       "\\item[nnet] 'nnet'\n",
       "\\item[numDeriv] 'numDeriv'\n",
       "\\item[openssl] 'openssl'\n",
       "\\item[parallel] 'parallel'\n",
       "\\item[pbdZMQ] 'pbdZMQ'\n",
       "\\item[pillar] 'pillar'\n",
       "\\item[pkgconfig] 'pkgconfig'\n",
       "\\item[plogr] 'plogr'\n",
       "\\item[plyr] 'plyr'\n",
       "\\item[prettyunits] 'prettyunits'\n",
       "\\item[processx] 'processx'\n",
       "\\item[prodlim] 'prodlim'\n",
       "\\item[progress] 'progress'\n",
       "\\item[promises] 'promises'\n",
       "\\item[ps] 'ps'\n",
       "\\item[purrr] 'purrr'\n",
       "\\item[quantmod] 'quantmod'\n",
       "\\item[R6] 'R6'\n",
       "\\item[randomForest] 'randomForest'\n",
       "\\item[rbokeh] 'rbokeh'\n",
       "\\item[RColorBrewer] 'RColorBrewer'\n",
       "\\item[Rcpp] 'Rcpp'\n",
       "\\item[RcppRoll] 'RcppRoll'\n",
       "\\item[readr] 'readr'\n",
       "\\item[readxl] 'readxl'\n",
       "\\item[recipes] 'recipes'\n",
       "\\item[rematch] 'rematch'\n",
       "\\item[repr] 'repr'\n",
       "\\item[reprex] 'reprex'\n",
       "\\item[reshape2] 'reshape2'\n",
       "\\item[rlang] 'rlang'\n",
       "\\item[rmarkdown] 'rmarkdown'\n",
       "\\item[rpart] 'rpart'\n",
       "\\item[rstudioapi] 'rstudioapi'\n",
       "\\item[rvest] 'rvest'\n",
       "\\item[scales] 'scales'\n",
       "\\item[selectr] 'selectr'\n",
       "\\item[shiny] 'shiny'\n",
       "\\item[sourcetools] 'sourcetools'\n",
       "\\item[spatial] 'spatial'\n",
       "\\item[splines] 'splines'\n",
       "\\item[SQUAREM] 'SQUAREM'\n",
       "\\item[stats] 'stats'\n",
       "\\item[stats4] 'stats4'\n",
       "\\item[stringi] 'stringi'\n",
       "\\item[stringr] 'stringr'\n",
       "\\item[survival] 'survival'\n",
       "\\item[sys] 'sys'\n",
       "\\item[tcltk] 'tcltk'\n",
       "\\item[tibble] 'tibble'\n",
       "\\item[tidyr] 'tidyr'\n",
       "\\item[tidyselect] 'tidyselect'\n",
       "\\item[tidyverse] 'tidyverse'\n",
       "\\item[timeDate] 'timeDate'\n",
       "\\item[tinytex] 'tinytex'\n",
       "\\item[tools] 'tools'\n",
       "\\item[translations] 'translations'\n",
       "\\item[TTR] 'TTR'\n",
       "\\item[utf8] 'utf8'\n",
       "\\item[utils] 'utils'\n",
       "\\item[uuid] 'uuid'\n",
       "\\item[viridisLite] 'viridisLite'\n",
       "\\item[whisker] 'whisker'\n",
       "\\item[withr] 'withr'\n",
       "\\item[xfun] 'xfun'\n",
       "\\item[xml2] 'xml2'\n",
       "\\item[xtable] 'xtable'\n",
       "\\item[xts] 'xts'\n",
       "\\item[yaml] 'yaml'\n",
       "\\item[zoo] 'zoo'\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "askpass\n",
       ":   'askpass'assertthat\n",
       ":   'assertthat'backports\n",
       ":   'backports'base\n",
       ":   'base'base64enc\n",
       ":   'base64enc'BH\n",
       ":   'BH'boot\n",
       ":   'boot'broom\n",
       ":   'broom'callr\n",
       ":   'callr'caret\n",
       ":   'caret'cellranger\n",
       ":   'cellranger'class\n",
       ":   'class'cli\n",
       ":   'cli'clipr\n",
       ":   'clipr'cluster\n",
       ":   'cluster'codetools\n",
       ":   'codetools'colorspace\n",
       ":   'colorspace'compiler\n",
       ":   'compiler'crayon\n",
       ":   'crayon'curl\n",
       ":   'curl'data.table\n",
       ":   'data.table'datasets\n",
       ":   'datasets'DBI\n",
       ":   'DBI'dbplyr\n",
       ":   'dbplyr'dichromat\n",
       ":   'dichromat'digest\n",
       ":   'digest'dplyr\n",
       ":   'dplyr'ellipsis\n",
       ":   'ellipsis'evaluate\n",
       ":   'evaluate'fansi\n",
       ":   'fansi'forcats\n",
       ":   'forcats'foreach\n",
       ":   'foreach'foreign\n",
       ":   'foreign'formatR\n",
       ":   'formatR'fs\n",
       ":   'fs'generics\n",
       ":   'generics'ggplot2\n",
       ":   'ggplot2'glmnet\n",
       ":   'glmnet'glue\n",
       ":   'glue'gower\n",
       ":   'gower'graphics\n",
       ":   'graphics'grDevices\n",
       ":   'grDevices'grid\n",
       ":   'grid'gtable\n",
       ":   'gtable'haven\n",
       ":   'haven'hexbin\n",
       ":   'hexbin'highr\n",
       ":   'highr'hms\n",
       ":   'hms'htmltools\n",
       ":   'htmltools'htmlwidgets\n",
       ":   'htmlwidgets'httpuv\n",
       ":   'httpuv'httr\n",
       ":   'httr'ipred\n",
       ":   'ipred'IRdisplay\n",
       ":   'IRdisplay'IRkernel\n",
       ":   'IRkernel'iterators\n",
       ":   'iterators'jsonlite\n",
       ":   'jsonlite'KernSmooth\n",
       ":   'KernSmooth'knitr\n",
       ":   'knitr'labeling\n",
       ":   'labeling'later\n",
       ":   'later'lattice\n",
       ":   'lattice'lava\n",
       ":   'lava'lazyeval\n",
       ":   'lazyeval'lubridate\n",
       ":   'lubridate'magrittr\n",
       ":   'magrittr'maps\n",
       ":   'maps'markdown\n",
       ":   'markdown'MASS\n",
       ":   'MASS'Matrix\n",
       ":   'Matrix'methods\n",
       ":   'methods'mgcv\n",
       ":   'mgcv'mime\n",
       ":   'mime'ModelMetrics\n",
       ":   'ModelMetrics'modelr\n",
       ":   'modelr'munsell\n",
       ":   'munsell'nlme\n",
       ":   'nlme'nnet\n",
       ":   'nnet'numDeriv\n",
       ":   'numDeriv'openssl\n",
       ":   'openssl'parallel\n",
       ":   'parallel'pbdZMQ\n",
       ":   'pbdZMQ'pillar\n",
       ":   'pillar'pkgconfig\n",
       ":   'pkgconfig'plogr\n",
       ":   'plogr'plyr\n",
       ":   'plyr'prettyunits\n",
       ":   'prettyunits'processx\n",
       ":   'processx'prodlim\n",
       ":   'prodlim'progress\n",
       ":   'progress'promises\n",
       ":   'promises'ps\n",
       ":   'ps'purrr\n",
       ":   'purrr'quantmod\n",
       ":   'quantmod'R6\n",
       ":   'R6'randomForest\n",
       ":   'randomForest'rbokeh\n",
       ":   'rbokeh'RColorBrewer\n",
       ":   'RColorBrewer'Rcpp\n",
       ":   'Rcpp'RcppRoll\n",
       ":   'RcppRoll'readr\n",
       ":   'readr'readxl\n",
       ":   'readxl'recipes\n",
       ":   'recipes'rematch\n",
       ":   'rematch'repr\n",
       ":   'repr'reprex\n",
       ":   'reprex'reshape2\n",
       ":   'reshape2'rlang\n",
       ":   'rlang'rmarkdown\n",
       ":   'rmarkdown'rpart\n",
       ":   'rpart'rstudioapi\n",
       ":   'rstudioapi'rvest\n",
       ":   'rvest'scales\n",
       ":   'scales'selectr\n",
       ":   'selectr'shiny\n",
       ":   'shiny'sourcetools\n",
       ":   'sourcetools'spatial\n",
       ":   'spatial'splines\n",
       ":   'splines'SQUAREM\n",
       ":   'SQUAREM'stats\n",
       ":   'stats'stats4\n",
       ":   'stats4'stringi\n",
       ":   'stringi'stringr\n",
       ":   'stringr'survival\n",
       ":   'survival'sys\n",
       ":   'sys'tcltk\n",
       ":   'tcltk'tibble\n",
       ":   'tibble'tidyr\n",
       ":   'tidyr'tidyselect\n",
       ":   'tidyselect'tidyverse\n",
       ":   'tidyverse'timeDate\n",
       ":   'timeDate'tinytex\n",
       ":   'tinytex'tools\n",
       ":   'tools'translations\n",
       ":   'translations'TTR\n",
       ":   'TTR'utf8\n",
       ":   'utf8'utils\n",
       ":   'utils'uuid\n",
       ":   'uuid'viridisLite\n",
       ":   'viridisLite'whisker\n",
       ":   'whisker'withr\n",
       ":   'withr'xfun\n",
       ":   'xfun'xml2\n",
       ":   'xml2'xtable\n",
       ":   'xtable'xts\n",
       ":   'xts'yaml\n",
       ":   'yaml'zoo\n",
       ":   'zoo'\n",
       "\n"
      ],
      "text/plain": [
       "       askpass     assertthat      backports           base      base64enc \n",
       "     \"askpass\"   \"assertthat\"    \"backports\"         \"base\"    \"base64enc\" \n",
       "            BH           boot          broom          callr          caret \n",
       "          \"BH\"         \"boot\"        \"broom\"        \"callr\"        \"caret\" \n",
       "    cellranger          class            cli          clipr        cluster \n",
       "  \"cellranger\"        \"class\"          \"cli\"        \"clipr\"      \"cluster\" \n",
       "     codetools     colorspace       compiler         crayon           curl \n",
       "   \"codetools\"   \"colorspace\"     \"compiler\"       \"crayon\"         \"curl\" \n",
       "    data.table       datasets            DBI         dbplyr      dichromat \n",
       "  \"data.table\"     \"datasets\"          \"DBI\"       \"dbplyr\"    \"dichromat\" \n",
       "        digest          dplyr       ellipsis       evaluate          fansi \n",
       "      \"digest\"        \"dplyr\"     \"ellipsis\"     \"evaluate\"        \"fansi\" \n",
       "       forcats        foreach        foreign        formatR             fs \n",
       "     \"forcats\"      \"foreach\"      \"foreign\"      \"formatR\"           \"fs\" \n",
       "      generics        ggplot2         glmnet           glue          gower \n",
       "    \"generics\"      \"ggplot2\"       \"glmnet\"         \"glue\"        \"gower\" \n",
       "      graphics      grDevices           grid         gtable          haven \n",
       "    \"graphics\"    \"grDevices\"         \"grid\"       \"gtable\"        \"haven\" \n",
       "        hexbin          highr            hms      htmltools    htmlwidgets \n",
       "      \"hexbin\"        \"highr\"          \"hms\"    \"htmltools\"  \"htmlwidgets\" \n",
       "        httpuv           httr          ipred      IRdisplay       IRkernel \n",
       "      \"httpuv\"         \"httr\"        \"ipred\"    \"IRdisplay\"     \"IRkernel\" \n",
       "     iterators       jsonlite     KernSmooth          knitr       labeling \n",
       "   \"iterators\"     \"jsonlite\"   \"KernSmooth\"        \"knitr\"     \"labeling\" \n",
       "         later        lattice           lava       lazyeval      lubridate \n",
       "       \"later\"      \"lattice\"         \"lava\"     \"lazyeval\"    \"lubridate\" \n",
       "      magrittr           maps       markdown           MASS         Matrix \n",
       "    \"magrittr\"         \"maps\"     \"markdown\"         \"MASS\"       \"Matrix\" \n",
       "       methods           mgcv           mime   ModelMetrics         modelr \n",
       "     \"methods\"         \"mgcv\"         \"mime\" \"ModelMetrics\"       \"modelr\" \n",
       "       munsell           nlme           nnet       numDeriv        openssl \n",
       "     \"munsell\"         \"nlme\"         \"nnet\"     \"numDeriv\"      \"openssl\" \n",
       "      parallel         pbdZMQ         pillar      pkgconfig          plogr \n",
       "    \"parallel\"       \"pbdZMQ\"       \"pillar\"    \"pkgconfig\"        \"plogr\" \n",
       "          plyr    prettyunits       processx        prodlim       progress \n",
       "        \"plyr\"  \"prettyunits\"     \"processx\"      \"prodlim\"     \"progress\" \n",
       "      promises             ps          purrr       quantmod             R6 \n",
       "    \"promises\"           \"ps\"        \"purrr\"     \"quantmod\"           \"R6\" \n",
       "  randomForest         rbokeh   RColorBrewer           Rcpp       RcppRoll \n",
       "\"randomForest\"       \"rbokeh\" \"RColorBrewer\"         \"Rcpp\"     \"RcppRoll\" \n",
       "         readr         readxl        recipes        rematch           repr \n",
       "       \"readr\"       \"readxl\"      \"recipes\"      \"rematch\"         \"repr\" \n",
       "        reprex       reshape2          rlang      rmarkdown          rpart \n",
       "      \"reprex\"     \"reshape2\"        \"rlang\"    \"rmarkdown\"        \"rpart\" \n",
       "    rstudioapi          rvest         scales        selectr          shiny \n",
       "  \"rstudioapi\"        \"rvest\"       \"scales\"      \"selectr\"        \"shiny\" \n",
       "   sourcetools        spatial        splines        SQUAREM          stats \n",
       " \"sourcetools\"      \"spatial\"      \"splines\"      \"SQUAREM\"        \"stats\" \n",
       "        stats4        stringi        stringr       survival            sys \n",
       "      \"stats4\"      \"stringi\"      \"stringr\"     \"survival\"          \"sys\" \n",
       "         tcltk         tibble          tidyr     tidyselect      tidyverse \n",
       "       \"tcltk\"       \"tibble\"        \"tidyr\"   \"tidyselect\"    \"tidyverse\" \n",
       "      timeDate        tinytex          tools   translations            TTR \n",
       "    \"timeDate\"      \"tinytex\"        \"tools\" \"translations\"          \"TTR\" \n",
       "          utf8          utils           uuid    viridisLite        whisker \n",
       "        \"utf8\"        \"utils\"         \"uuid\"  \"viridisLite\"      \"whisker\" \n",
       "         withr           xfun           xml2         xtable            xts \n",
       "       \"withr\"         \"xfun\"         \"xml2\"       \"xtable\"          \"xts\" \n",
       "          yaml            zoo \n",
       "        \"yaml\"          \"zoo\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "installed.packages()[,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3529539-592f-47ae-ba7b-b50a988367b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################################/#\n",
    "######################### VERSION 0.1 - AUTOMATED CLEAN PROCESS FOR CEHD ########################/#\n",
    "#################################################################################################/#\n",
    "\n",
    "\n",
    "##################################################################/#\n",
    "############################ PREAMBULE ############################\n",
    "##################################################################/#\n",
    "\n",
    "## Creation date : 08 jan 2019\n",
    "## Last version updated : 16/12/2019\n",
    "## List of updates :\n",
    "# - Add lines 109 to 114 : Import CSV with sep = \";\" for new CEHD data\n",
    "# - Modification line 221 IMIS_SUBSTANCE_CODE : factor(gsub(\" \", \"0\", sprintf(\"%4s\", database$IMIS_SUBSTANCE_CODE)))\n",
    "# - Modification line 257 ZIP_CODE : factor(gsub(\" \", \"0\", sprintf(\"%5s\", database$ZIP_CODE)))\n",
    "\n",
    "##################################################################/#\n",
    "\n",
    "CLEANING_PROCESS <- function(){\n",
    "  \n",
    "  ##################################################################/#\n",
    "  ######################### PACKAGES LOADING #######################/# \n",
    "  ##################################################################/#\n",
    "  \n",
    "  vec_packages <- installed.packages()[,1]\n",
    "  \n",
    "  \n",
    "  if(\"XML\" %in% vec_packages){\n",
    "    \n",
    "    library(XML)\n",
    "    library(methods)\n",
    "    \n",
    "  }else{\n",
    "    \n",
    "    install.packages(\"XML\")\n",
    "    install.packages(\"methods\")\n",
    "  }\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0021b61-49fe-478f-8110-662be01e01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "  ##################################################################/#\n",
    "  \n",
    "  ##################################################################/#\n",
    "  ################## IMPORTATION OF ALL CEHD FILES #################/#\n",
    "  ##################################################################/#\n",
    "  \n",
    "  one_database <- readline(\"Do you already have a database in one file? (Y/N) \")\n",
    "  \n",
    "  if(one_database %in% c(\"Y\", \"y\", \"O\", \"o\")){\n",
    "    \n",
    "    LOADING <- 'R'\n",
    "    \n",
    "    while(LOADING %in% c('R', 'r')){\n",
    "      \n",
    "      separator <- readline(\"Please, import the file and precise the separator used to divide columns: \")\n",
    "      interactive_database_pathway <- file.choose()\n",
    "      \n",
    "      if(substring(interactive_database_pathway, (nchar(interactive_database_pathway)-2), nchar(interactive_database_pathway)) == 'csv'){\n",
    "        \n",
    "        database <- read.csv(interactive_database_pathway, header = TRUE, sep = separator)\n",
    "        \n",
    "      }else{\n",
    "        \n",
    "        database <- read.table(interactive_database_pathway, header = TRUE, sep = separator)\n",
    "        \n",
    "      }\n",
    "      \n",
    "      cat(nrow(database), \"rows and\", ncol(database), \"columns have been loaded.\")\n",
    "      LOADING <- readline(\"Do you want to continue (C) or retry (R): \")\n",
    "      \n",
    "    }\n",
    "    \n",
    "  }else{\n",
    "    \n",
    "    ## All files need to be in the same folder\n",
    "    ## Computer can crash... Need a find a better way. \n",
    "    \n",
    "    cat(\"The program will automatically load all your files to compile them.\\n \n",
    "        Please, indicate the folder where your files are registered (and only the files).\\n\n",
    "        /!\\ Be carefull, it could be very long (~15-45 min each file if xml extension.\\n\")\n",
    "    interactive_folder_pathway <- choose.dir(default = getwd(), caption = \"Select folder\")\n",
    "    vec_files <- list.files(interactive_folder_pathway)\n",
    "    list_files <- list()\n",
    "    \n",
    "    for(i in 1 : length(vec_files)){\n",
    "      \n",
    "      cat(\"Loop\", i, \"-\", format(Sys.time(), \"%X\"), \"\\n\")\n",
    "      \n",
    "      if(substring(vec_files[i], (nchar(vec_files[i])-2), nchar(vec_files[i])) == \"xml\"){\n",
    "        \n",
    "        tmp <- xmlToDataFrame(paste0(interactive_folder_pathway,\"/\",vec_files[i])); tmp <<- tmp\n",
    "        list_files[[i]] <- tmp\n",
    "        \n",
    "      }else{ #csv or txt\n",
    "        \n",
    "        if(substring(vec_files[i], (nchar(vec_files[i])-2), nchar(vec_files[i])) == \"csv\"){\n",
    "          \n",
    "          if(length(grep(\"[|]\", readLines(paste0(interactive_folder_pathway,\"/\",vec_files[i]), 1))) > 0){\n",
    "            \n",
    "            list_files[[i]] <- read.csv(paste0(interactive_folder_pathway,\"/\",vec_files[i]), header = TRUE, sep = \"|\")\n",
    "            \n",
    "          }\n",
    "          \n",
    "          if(length(grep(\"[,]\", readLines(paste0(interactive_folder_pathway,\"/\",vec_files[i]), 1))) > 0){\n",
    "            \n",
    "            \n",
    "            list_files[[i]] <- read.csv(paste0(interactive_folder_pathway,\"/\",vec_files[i]), header = TRUE, sep = \",\")\n",
    "            \n",
    "          }\n",
    "          \n",
    "          if(length(grep(\"[;]\", readLines(paste0(interactive_folder_pathway,\"/\",vec_files[i]), 1))) > 0){\n",
    "            \n",
    "            \n",
    "            list_files[[i]] <- read.csv(paste0(interactive_folder_pathway,\"/\",vec_files[i]), header = TRUE, sep = \";\")\n",
    "            \n",
    "          }\n",
    "          \n",
    "        }\n",
    "        \n",
    "        if(substring(vec_files[i], (nchar(vec_files[i])-2), nchar(vec_files[i])) == \"txt\"){ #not 'else' in case of xls files\n",
    "          \n",
    "          \n",
    "          list_files[[i]] <- read.table(paste0(interactive_folder_pathway,\"/\",vec_files[i]), header = TRUE)\n",
    "          \n",
    "        }\n",
    "        \n",
    "      }\n",
    "      \n",
    "      saveRDS(list_files, \"list_CEHD.rds\")\n",
    "      gc(reset = TRUE)\n",
    "      \n",
    "    }\n",
    "    \n",
    "    list_files <<- list_files\n",
    "    cat(\"End: \", print(Sys.time()), \",\", length(list_files), \"file(s) loaded\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ###################################################################\n",
    "    \n",
    "    \n",
    "    ###################################################################\n",
    "    ################# STANDARDIZATION and COMPILATION #################\n",
    "    ######################### ALL CEHD FILES ##########################\n",
    "    ###################################################################\n",
    "    \n",
    "    ## From first observation :\n",
    "    \n",
    "    ## 'blank_sample' and 'blank_used' are used for the same information and need to be standardized.\n",
    "    ## 'instrument_type' were not in the first years. Need to be added for some files.\n",
    "    ## 'eight_hour_twa_calc' and 'eight_hr_twa_calc' are the same but not in all files, standardization and addition.\n",
    "    \n",
    "    ## Several settings to apply, loop more relevant.\n",
    "    \n",
    "    \n",
    "    ################# STANDARDIZATION #################\n",
    "    \n",
    "    for (i in 1 : length(list_files)){\n",
    "    \n",
    "      ## Standardization in CAPITALS\n",
    "      colnames(list_files[[i]]) <- toupper(colnames(list_files[[i]]))\n",
    "      \n",
    "      ## Standardization of BLANK\n",
    "      colnames(list_files[[i]]) <- gsub(\"BLANK_SAMPLE\", \"BLANK_USED\", colnames(list_files[[i]]))\n",
    "      \n",
    "      \n",
    "      ## Adding INSTRUMENT_TYPE\n",
    "      if(!'INSTRUMENT_TYPE' %in% colnames(list_files[[i]])){\n",
    "        list_files[[i]]$INSTRUMENT_TYPE <- rep(NA, nrow(list_files[[i]]))\n",
    "      }\n",
    "      \n",
    "      ## Standardization of EIGHT_HR\n",
    "      if('EIGHT_HR_TWA_CALC' %in% colnames(list_files[[i]]) | 'EIGHT_HOUR_TWA_CALC' %in% colnames(list_files[[i]])){\n",
    "        colnames(list_files[[i]]) <- gsub(\"EIGHT_HR_TWA_CALC\", \"EIGHT_HOUR_TWA_CALC\", colnames(list_files[[i]]))\n",
    "      }else{\n",
    "        list_files[[i]]$EIGHT_HOUR_TWA_CALC <- rep(NA, nrow(list_files[[i]]))\n",
    "      }\n",
    "      \n",
    "      \n",
    "      list_files[[i]] <- list_files[[i]][, order(colnames(list_files[[i]]))]\n",
    "      \n",
    "      list_files[[i]] <-  apply(list_files[[i]], 2, as.character)\n",
    "      \n",
    "    }\n",
    "    \n",
    "    ################# COMPILATION #################\n",
    "    \n",
    "    database <- do.call(rbind, list_files)\n",
    "    database <- as.data.frame(database)\n",
    "    \n",
    "    ################# RE-FORMAT #################\n",
    "    \n",
    "    ## Re adjusting type and format of variables\n",
    "    \n",
    "    lct <- Sys.getlocale(\"LC_TIME\"); Sys.setlocale(\"LC_TIME\", \"C\") #format error for date without this command\n",
    "    \n",
    "    database <- within(database, {\n",
    "      \n",
    "      AIR_VOLUME_SAMPLED <- as.numeric(as.character(AIR_VOLUME_SAMPLED))\n",
    "      \n",
    "      BLANK_USED <- factor(BLANK_USED, levels = c('Y', 'N'))\n",
    "      \n",
    "      CITY <- as.character(CITY)\n",
    "      \n",
    "      DATE_REPORTED <- as.character(tolower(DATE_REPORTED))\n",
    "      DATE_REPORTED <- ifelse(nchar(DATE_REPORTED) == 11 , as.character(as.Date(DATE_REPORTED, format = \"%Y-%b-%d\")), \n",
    "                              ifelse(nchar(DATE_REPORTED) == 19, as.character(as.Date(DATE_REPORTED, format = '%Y/%m/%d')), \n",
    "                                     as.character(as.Date(DATE_REPORTED, format = '%Y-%m-%d'))))\n",
    "      DATE_REPORTED <- as.Date(DATE_REPORTED, format = '%Y-%m-%d')\n",
    "      \n",
    "      DATE_SAMPLED <- as.character(tolower(DATE_SAMPLED))\n",
    "      DATE_SAMPLED <- ifelse(nchar(DATE_SAMPLED) == 11 , as.character(as.Date(DATE_SAMPLED, format = \"%Y-%b-%d\")), \n",
    "                             ifelse(nchar(DATE_SAMPLED) == 19, as.character(as.Date(DATE_SAMPLED, format = '%Y/%m/%d')), \n",
    "                                    as.character(as.Date(DATE_SAMPLED, format = '%Y-%m-%d'))))\n",
    "      DATE_SAMPLED <- as.Date(DATE_SAMPLED, format = '%Y-%m-%d')\n",
    "      \n",
    "      EIGHT_HOUR_TWA_CALC <- factor(EIGHT_HOUR_TWA_CALC, levels = c('Y', 'N'))\n",
    "      \n",
    "      ESTABLISHMENT_NAME <- as.character(ESTABLISHMENT_NAME)\n",
    "      \n",
    "      FIELD_NUMBER <- as.character(FIELD_NUMBER)\n",
    "      \n",
    "      IMIS_SUBSTANCE_CODE <- factor(gsub(\" \", \"0\", sprintf(\"%4s\", database$IMIS_SUBSTANCE_CODE)))\n",
    "      INSPECTION_NUMBER <- factor(INSPECTION_NUMBER)\n",
    "      \n",
    "      INSTRUMENT_TYPE <- as.character(INSTRUMENT_TYPE) #need to be cleaned before levels\n",
    "      \n",
    "      LAB_NUMBER <- factor(LAB_NUMBER)\n",
    "      \n",
    "      NAICS_CODE <- as.character(NAICS_CODE)\n",
    "      NAICS_CODE <- ifelse(nchar(NAICS_CODE) < 6, NA, NAICS_CODE) #deletion of missing or 0 NAICS CODE\n",
    "      \n",
    "      OFFICE_ID <- factor(OFFICE_ID)\n",
    "      \n",
    "      QUALIFIER <- as.character(QUALIFIER) #need to be cleaned before levels\n",
    "      \n",
    "      SAMPLE_RESULT <- as.numeric(as.character(database$SAMPLE_RESULT))\n",
    "      \n",
    "      ## Should have only 4 levels according to CEHD information\n",
    "      SAMPLE_TYPE <- factor(SAMPLE_TYPE) #A B BL BU L M P S U W WB Z\n",
    "      \n",
    "      SAMPLE_WEIGHT <- as.numeric(as.character(SAMPLE_WEIGHT))\n",
    "      \n",
    "      ## Maybe need a cleaning. Kept it as factor for now on.\n",
    "      SAMPLING_NUMBER <- factor(SAMPLING_NUMBER)\n",
    "      \n",
    "      SIC_CODE <- factor(SIC_CODE)\n",
    "      \n",
    "      STATE <- factor(STATE)\n",
    "      \n",
    "      # Label of IMIS code, not the same number of levels though.\n",
    "      SUBSTANCE <- as.character(SUBSTANCE)\n",
    "      \n",
    "      # Time in minutes\n",
    "      TIME_SAMPLED <- as.numeric(as.character(TIME_SAMPLED))\n",
    "      \n",
    "      UNIT_OF_MEASUREMENT <- as.character(UNIT_OF_MEASUREMENT) # #need to be cleaned before levels\n",
    "      \n",
    "      ZIP_CODE <- factor(gsub(\" \", \"0\", sprintf(\"%5s\", database$ZIP_CODE)))\n",
    "      \n",
    "    })\n",
    "    \n",
    "    \n",
    "    database$YEAR <- factor(substring(database$DATE_SAMPLED, 1, 4))\n",
    "    saveRDS(database, \"database_all_CEHD.rds\")\n",
    "    \n",
    "  }\n",
    "}\n",
    "  \n",
    "\n",
    "CLEANING_PROCESS()\n",
    "\n",
    "\n",
    "  ##################################################################/#\n",
    "  \n",
    "  \n",
    "  # ##################################################################/#\n",
    "  # ############################ CLEANING #############################\n",
    "  # ##################################################################/#\n",
    "  # \n",
    "  #load db\n",
    "  database <- readRDS(\"C:\\\\Users\\\\phisar\\\\Dropbox (IRSST)\\\\PhD\\\\Projet IMIS\\\\Rï¿½sultats\\\\IMIS_ND_predict\\\\CEHD 84_18\\\\database_all_CEHD.rds\")\n",
    "  dim(database) #[1] 2395071      26\n",
    "  table(database$YEAR)\n",
    "  names(database)\n",
    "  #[1] \"AIR_VOLUME_SAMPLED\"  \"BLANK_USED\"          \"CITY\"                \"DATE_REPORTED\"       \"DATE_SAMPLED\"       \n",
    "  #[6] \"EIGHT_HOUR_TWA_CALC\" \"ESTABLISHMENT_NAME\"  \"FIELD_NUMBER\"        \"IMIS_SUBSTANCE_CODE\" \"INSPECTION_NUMBER\"  \n",
    "  #[11] \"INSTRUMENT_TYPE\"     \"LAB_NUMBER\"          \"NAICS_CODE\"          \"OFFICE_ID\"           \"QUALIFIER\"          \n",
    "  #[16] \"SAMPLE_RESULT\"       \"SAMPLE_TYPE\"         \"SAMPLE_WEIGHT\"       \"SAMPLING_NUMBER\"     \"SIC_CODE\"           \n",
    "  #[21] \"STATE\"               \"SUBSTANCE\"           \"TIME_SAMPLED\"        \"UNIT_OF_MEASUREMENT\" \"ZIP_CODE\"           \n",
    "  #[26] \"YEAR\"           \n",
    "  database$IMIS_SUBSTANCE_CODE <- as.character(database$IMIS_SUBSTANCE_CODE)\n",
    "  #class(database$IMIS_SUBSTANCE_CODE)\n",
    "  #table(database$IMIS_SUBSTANCE_CODE)\n",
    "  #sort(unique(database$IMIS_SUBSTANCE_CODE))\n",
    "  length(unique(database$IMIS_SUBSTANCE_CODE)) #[1] 1159\n",
    "  str(database)\n",
    "  database$INSPECTION_NUMBER <- as.character(database$INSPECTION_NUMBER)\n",
    "  database$SAMPLING_NUMBER <- as.character(database$SAMPLING_NUMBER)\n",
    "  \n",
    "  #remove white spaces left and right of variables\n",
    "  database$INSPECTION_NUMBER <- trimws(database$INSPECTION_NUMBER)\n",
    "  database$SAMPLING_NUMBER <- trimws(database$SAMPLING_NUMBER)\n",
    "  \n",
    "  ### Setting data.frame to count elimination\n",
    "  reasons <- data.frame(YEAR = min(as.character(database$YEAR)) : max(as.character(database$YEAR)))\n",
    "   \n",
    "    \n",
    "  # ##################### N01: Blanks ####\n",
    "  # N01 removing blanks from the blank_used variable (other blanks identified later by qualifier)\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[database$BLANK_USED != 'N'])\n",
    "  reasons$N01[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "   \n",
    "  database <- database[database$BLANK_USED == 'N', ]\n",
    "  table(database$BLANK_USED)\n",
    "  #Y       N \n",
    "  #0 1958557\n",
    "  sum(reasons$N01,na.rm = TRUE)\n",
    "  length(database[,1]) #1958557(-436514)\n",
    "  \n",
    "  \n",
    "  # ##################### N02: Personal measurements ####\n",
    "  # N02 removing non personal samples\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[database$SAMPLE_TYPE != 'P'])\n",
    "  reasons$N02[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[database$SAMPLE_TYPE == 'P', ] #excluding all things that are not P (keeping P only)\n",
    "  table(database$SAMPLE_TYPE)\n",
    "  #A       B      BL      BU       L       M       P       S       U       W      WB       Z \n",
    "  #0       0       0       0       0       0 1506202       0       0       0       0       0\n",
    "  sum(reasons$N02,na.rm = TRUE)\n",
    "  length(database[,1]) #1506271(-452286)\n",
    "  \n",
    "  \n",
    "  # ##################### N03 Excluding substances with few samples ####\n",
    "  # Store the 81 substances of the 2011 initial cleaning procedure in an object\n",
    "  sub_list_81 <-c('0040','0230','0260','0360','0430','0491','0685','0720','0731','1073','1290','1520','1560',\n",
    "               '1591','1620','1730','1790','1840','2270','2280','2460','2571','2590','2610','9010','9020','9130','9135','C141',\n",
    "               '0170','0320','0435','0440','0460','0490','0686','0689','0692','0700','0710','0726','0730','0830','0860','1037','1040',\n",
    "               '1060','1080','1190','1280','1371','1377','1380','1385','1430','1534','1536','1631','1660','1675','1720','1774','1860','2020',\n",
    "               '2037','2040','2170','2180','2240','2260','2290','2310','2430','2470','2490','2505','2580','9015','T177','V109','S103')\n",
    "  sub_list_81 <- sort(sub_list_81)\n",
    "  \n",
    "  # Store all substances with >100 records in an object\n",
    "  subst <- data.frame(table(database$IMIS_SUBSTANCE_CODE))\n",
    "  names(subst) <-c('code','n')\n",
    "  subst <- subst[order(-subst$n),]\n",
    "  nrow(subst) #[1] 978\n",
    "  subst$name <- database$SUBSTANCE[match(subst$code,database$IMIS_SUBSTANCE_CODE)]\n",
    "  subst <- subst[subst$n>=100,]\n",
    "  nrow(subst) #[1] 265\n",
    "  #View(subst)\n",
    "  # remove codes which do not correspond to chemical substances\n",
    "  subst_all <- subst[!is.element(subst$code,c('G301','G302','Q115','T110','M125','Q116','Q100','S325')),]\n",
    "  nrow(subst_all) #[1] 257\n",
    "  sub_list_all <- sort(as.character(subst_all$code))\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[!is.element(database$IMIS_SUBSTANCE_CODE,sub_list_all)])\n",
    "  reasons$N03[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[is.element(database$IMIS_SUBSTANCE_CODE,sub_list_all),] #restrict to subst in the list\n",
    "  length(unique(database$IMIS_SUBSTANCE_CODE)) #257\n",
    "  sort(unique(database$IMIS_SUBSTANCE_CODE))\n",
    "  length(unique(database$SUBSTANCE)) #281 (this number is higher than 257 because substance names are not standardized)\n",
    "  sort(unique(database$SUBSTANCE))\n",
    "  \n",
    "  sum(reasons$N03,na.rm = TRUE)\n",
    "  length(database[,1]) #1387254(-118948)\n",
    "  \n",
    "  \n",
    "  # ##################### Preparation of conversion tables for QUALIFIER and UNIT_OF_MEASUREMENT ####\n",
    "  library(writexl)\n",
    " \n",
    "  #### QUALIFIER\n",
    "  #### load table from 2011 ###/#\n",
    "  #qual.conv <- read.table(\"qual.conv.new.csv\", header=T, sep=\",\", stringsAsFactor=F)\n",
    "  #table(qual.conv$clean)\n",
    "  # B       BLK eliminate        ND         S sample OK         W \n",
    "  #19        51       161        73         6       332        10 \n",
    "  #write_xlsx(x = qual.conv, path = \"qual.conv.xlsx\", col_names = TRUE)\n",
    "  \n",
    "  #### new 2020 table ###/#: creation of a new conversion table for QUALIFIER variable\n",
    "  # replace NAs in the qualifier variable by \"raw was NA\"\n",
    "  class(database$QUALIFIER)\n",
    "  length(database$QUALIFIER) #[1] 1387254\n",
    "  sum(is.na(database$QUALIFIER)) #[1] 751060\n",
    "  database$QUALIFIER[is.na(database$QUALIFIER)] <- \"raw was NA\"\n",
    "  qualif <- data.frame(table(database$QUALIFIER))\n",
    "  names(qualif) <-c('raw','n')\n",
    "  #nrow(qualif) \n",
    "  sum(qualif$n) #[1] 1387254\n",
    "  #write_xlsx(x = qualif, path = \"qualif_new.xlsx\", col_names = TRUE)\n",
    "  qualif.conv.2020 <- read.csv('C:\\\\Users\\\\phisar\\\\Dropbox (IRSST)\\\\PhD\\\\Projet IMIS\\\\Rï¿½sultats\\\\IMIS_ND_predict\\\\CEHD 84_18\\\\Conversion tables\\\\qualif_new_2020.csv',sep=\";\", header=T)\n",
    "  qualif.conv.2020$clean <- as.character(qualif.conv.2020$clean)\n",
    "  qualif.conv.2020$raw <- as.character(qualif.conv.2020$raw)\n",
    "  qualif.conv.2020$possible_bulk <- as.character(qualif.conv.2020$possible_bulk)\n",
    "  table(qualif.conv.2020$clean)\n",
    "  #B       BLK  eliminate        ND         S sample OK         W \n",
    "  #1         7        137        49         6        12         1 \n",
    "  \n",
    "  #### UNIT_OF_MEASUREMENT\n",
    "  #### load table from 2011 ###/#\n",
    "  #unit <- read.table(\"unit.new.csv\", header=T, sep=\",\", stringsAsFactor=F)\n",
    "  #table(unit$clean)\n",
    "  #          % eliminate         F         M         P         X         Y \n",
    "  #1         3        36         4         2         2         2         1\n",
    "  #write_xlsx(x = unit, path = \"unit.new.xlsx\", col_names = TRUE)\n",
    "  \n",
    "  #### new 2020 table ###/#: creation of a new conversion table for UNIT_OF_MEASUREMENT variable\n",
    "  # replace NAs in the UNIT_OF_MEASUREMENT variable by \"raw was NA\"\n",
    "  class(database$UNIT_OF_MEASUREMENT)\n",
    "  length(database$UNIT_OF_MEASUREMENT) #[1] 1387254\n",
    "  sum(is.na(database$UNIT_OF_MEASUREMENT)) #[1] 29836\n",
    "  database$UNIT_OF_MEASUREMENT[is.na(database$UNIT_OF_MEASUREMENT)] <- \"raw was NA\"\n",
    "  unit_2020 <- data.frame(table(database$UNIT_OF_MEASUREMENT))\n",
    "  names(unit_2020) <-c('raw','n')\n",
    "  nrow(unit_2020) \n",
    "  sum(unit_2020$n) #[1] 1387254\n",
    "  #write_xlsx(x = unit_2020, path = \"unit_conv.xlsx\", col_names = TRUE)\n",
    "  unit.conv.2020 <- read.csv('C:\\\\Users\\\\phisar\\\\Dropbox (IRSST)\\\\PhD\\\\Projet IMIS\\\\Rï¿½sultats\\\\IMIS_ND_predict\\\\CEHD 84_18\\\\Conversion tables\\\\unit_conv_2020.csv',sep=\";\", header=T)\n",
    "  unit.conv.2020$clean <- as.character(unit.conv.2020$clean)\n",
    "  unit.conv.2020$raw <- as.character(unit.conv.2020$raw)\n",
    "  table(unit.conv.2020$clean)\n",
    "  #          % eliminate         F         M         P         X         Y \n",
    "  #2         1        22         4         2         2         2         1\n",
    "  \n",
    "  \n",
    "  ##Add a column that indicates that the sample is censored ONLY based on the Qualifier variable with\n",
    "  #approximative '<' signs\n",
    "  database$CENSORED <- rep('N',length(database$IMIS_SUBSTANCE_CODE))\n",
    "  database$CENSORED[database$QUALIFIER==\"-<\"] <- \"Y\"\n",
    "  database$CENSORED[database$QUALIFIER==\"  <\"] <- \"Y\"\n",
    "  database$CENSORED[database$QUALIFIER==\" =<\"] <- \"Y\"\n",
    "  database$CENSORED[database$QUALIFIER==\"@<\"] <- \"Y\"\n",
    "  database$CENSORED[database$QUALIFIER==\"@<=\"] <- \"Y\"\n",
    "  database$CENSORED[database$QUALIFIER==\"@=<\"] <- \"Y\"\n",
    "  database$CENSORED[database$QUALIFIER==\"<\"] <- \"Y\"\n",
    "  database$CENSORED[database$QUALIFIER==\"< =\"] <- \"Y\"\n",
    "  database$CENSORED[database$QUALIFIER==\"<@\"] <- \"Y\"\n",
    "  database$CENSORED[database$QUALIFIER==\"<=\"] <- \"Y\"\n",
    "  database$CENSORED[database$QUALIFIER==\"<= 0\"] <- \"Y\"\n",
    "  database$CENSORED[database$QUALIFIER==\"= <\"] <- \"Y\"\n",
    "  database$CENSORED[database$QUALIFIER==\"=<\"] <- \"Y\"\n",
    "  database$CENSORED[database$QUALIFIER==\"=<@\"] <- \"Y\"\n",
    "  \n",
    "  \n",
    "  # \"raw was NA\" transformed into EMPTY in QUALIFIER\n",
    "  length(database$QUALIFIER[is.na(database$QUALIFIER)]) #0\n",
    "  length(database$QUALIFIER[database$QUALIFIER==\"raw was NA\"]) #751060\n",
    "  database$QUALIFIER[database$QUALIFIER==\"raw was NA\"] <- ''\n",
    "  length(database$QUALIFIER[database$QUALIFIER==\"raw was NA\"]) #0\n",
    "  \n",
    "  # NAs transformed into 0 in SAMPLE_RESULT\n",
    "  database$SAMPLE_RESULT_2 <- database$SAMPLE_RESULT\n",
    "  length(database$SAMPLE_RESULT_2[is.na(database$SAMPLE_RESULT_2)]) #39131\n",
    "  database$SAMPLE_RESULT_2[is.na(database$SAMPLE_RESULT_2)] <- 0\n",
    "  length(database$SAMPLE_RESULT_2[is.na(database$SAMPLE_RESULT_2)]) #0\n",
    "  \n",
    "  \n",
    "  \n",
    "  ##################### Standardisation of qualifier variable ##################### \n",
    "  #####Removing samples: Qualifier suggests ND but result is >0\n",
    "  # ##################### N08 / N29 qualifier suggests ND but sample result is not null ####\n",
    "  # N08\n",
    "  temp <- database[(database$SAMPLE_RESULT_2>0 & database$CENSORED!=\"Y\" &\n",
    "                                is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"ND\"]))),]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[(database$SAMPLE_RESULT_2>0 & database$CENSORED!=\"Y\" &\n",
    "                                    is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"ND\"])))])\n",
    "  reasons$N08[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!(database$SAMPLE_RESULT_2>0 & database$CENSORED!=\"Y\" &\n",
    "                          is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"ND\"]))), ] #exclusion\n",
    "  sum(reasons$N08,na.rm = TRUE)\n",
    "  length(database[,1]) #1386387(-867)\n",
    "  \n",
    "  # N29\n",
    "  temp <- database[(database$SAMPLE_RESULT_2>0 & (database$CENSORED==\"Y\" | \n",
    "                   is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"ND\"])))),]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[(database$SAMPLE_RESULT_2>0 & (database$CENSORED==\"Y\" | \n",
    "                   is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"ND\"]))))])\n",
    "  reasons$N29[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!(database$SAMPLE_RESULT_2>0 & (database$CENSORED==\"Y\" | \n",
    "                         is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"ND\"])))),] #exclusion\n",
    "  sum(reasons$N29,na.rm = TRUE)\n",
    "  length(database[,1]) #1377502(-8885)\n",
    "  \n",
    "  \n",
    "  #####Removing samples: Qualifier conflicting with unit of measurement / sample type, or judged 'to be eliminated'\n",
    "  #cleaning unit of measurement\n",
    "  \n",
    "  database$UNIT_OF_MEASUREMENT_2 <- database$UNIT_OF_MEASUREMENT\n",
    "  unik.clean <- unique(unit.conv.2020$clean)\n",
    "  \n",
    "  for (j in 1:length(unik.clean))\n",
    "  {\n",
    "    one.clean <- as.character(unik.clean)[j]\n",
    "    raw.values <- as.character(unit.conv.2020$raw[unit.conv.2020$clean==one.clean])\n",
    "    database$UNIT_OF_MEASUREMENT_2[is.element(database$UNIT_OF_MEASUREMENT, raw.values)] <- one.clean \n",
    "  }\n",
    "  \n",
    "  as.data.frame(table(database$UNIT_OF_MEASUREMENT))\n",
    "  table(database$UNIT_OF_MEASUREMENT_2)\n",
    "  \n",
    "  \n",
    "  # ##################### N04: qualifier=BLK and not possible bulk # elimination ####\n",
    "  temp <- database[is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"BLK\" & \n",
    "                                                                           qualif.conv.2020$possible_bulk==\"N\"])),]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"BLK\" & \n",
    "                                                                                         qualif.conv.2020$possible_bulk==\"N\"]))])\n",
    "  reasons$N04[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"BLK\" & \n",
    "                                                                                qualif.conv.2020$possible_bulk==\"N\"])),] #exclusion\n",
    "  sum(reasons$N04,na.rm = TRUE)\n",
    "  length(database[,1]) #1377481(-21)\n",
    "  \n",
    "  \n",
    "  # ##################### N05: qualifier deemed not interpretable and record is to be eliminated ####\n",
    "  temp <- database[is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"eliminate\"])),]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"eliminate\"]))])\n",
    "  reasons$N05[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"eliminate\"])),] #exclusion\n",
    "  sum(reasons$N05,na.rm = TRUE)\n",
    "  length(database[,1]) #1377022(-459)\n",
    "  \n",
    "  \n",
    "  # ##################### N06 / N07: qualifier conflicting with sample type ####\n",
    "  temp <- database[is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"B\" | qualif.conv.2020$clean==\"W\"])),]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"B\" | qualif.conv.2020$clean==\"W\"]))])\n",
    "  reasons$N0607[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"B\" | qualif.conv.2020$clean==\"W\"])),] #exclusion\n",
    "  sum(reasons$N0607,na.rm = TRUE)\n",
    "  length(database[,1]) #1376771(-251)\n",
    "  \n",
    "  \n",
    "  # ##################### N09: qualifier=BLK and a possible bulk as judged by researcher and variable blank_used says NO and sample type is not bulk, final result=eliminate ####\n",
    "  temp <- database[is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"BLK\" & qualif.conv.2020$possible_bulk==\"Y\"])) & is.element(database$BLANK_USED,\"N\"),]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"BLK\" & qualif.conv.2020$possible_bulk==\"Y\"])) & is.element(database$BLANK_USED,\"N\")])\n",
    "  reasons$N09[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!is.element(database$QUALIFIER, c(qualif.conv.2020$raw[qualif.conv.2020$clean==\"BLK\" & qualif.conv.2020$possible_bulk==\"Y\"])) & is.element(database$BLANK_USED,\"N\"),] #exclusion\n",
    "  sum(reasons$N09,na.rm = TRUE)\n",
    "  length(database[,1]) #1376453(-318)\n",
    "  \n",
    "  \n",
    "  # ##################### N10: combustion related : eliminate ####\n",
    "  temp <- database[is.element(database$QUALIFIER, c(\"COMB\",'COMD','com','comb')),]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[is.element(database$QUALIFIER, c(\"COMB\",'COMD','com','comb'))])\n",
    "  reasons$N10[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!is.element(database$QUALIFIER, c(\"COMB\",'COMD','com','comb')),] #exclusion\n",
    "  sum(reasons$N10,na.rm = TRUE)\n",
    "  length(database[,1]) #1376258(-195)\n",
    "  \n",
    "  \n",
    "  # ##################### N11: qualifier suggest fibers (F) but F not relevant for substance ####\n",
    "  temp <- database[database$QUALIFIER==\"F\" & database$IMIS_SUBSTANCE_CODE!=9020,]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[database$QUALIFIER==\"F\" & database$IMIS_SUBSTANCE_CODE!=9020])\n",
    "  reasons$N11[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!(database$QUALIFIER==\"F\" & database$IMIS_SUBSTANCE_CODE!=9020),] #exclusion\n",
    "  sum(reasons$N11,na.rm = TRUE)\n",
    "  length(database[,1]) #1376256(-2)\n",
    "  \n",
    "  \n",
    "  # ##################### N13: 'Y' qualifier value judged possible 'Ytrium', deemed OK for the generic particles category only : 9135 ####\n",
    "  temp <- database[database$QUALIFIER==\"Y\" & database$IMIS_SUBSTANCE_CODE!=9135,]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[database$QUALIFIER==\"Y\" & database$IMIS_SUBSTANCE_CODE!=9135])\n",
    "  reasons$N13[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!(database$QUALIFIER==\"Y\" & database$IMIS_SUBSTANCE_CODE!=9135),] #exclusion\n",
    "  sum(reasons$N13,na.rm = TRUE)\n",
    "  length(database[,1]) #1376206(-50)\n",
    "  \n",
    "  \n",
    "  # ##################### N16: measure is approximate (to be eliminated) ####\n",
    "  temp <- database[is.element(database$QUALIFIER,c(\"@\",\" @\",\"@<\",\"@=<\",\"@<=\",\"<@\",\"=<@\",\"EST\")),]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[is.element(database$QUALIFIER,c(\"@\",\" @\",\"@<\",\"@=<\",\"@<=\",\"<@\",\"=<@\",\"EST\"))])\n",
    "  reasons$N16[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!is.element(database$QUALIFIER,c(\"@\",\" @\",\"@<\",\"@=<\",\"@<=\",\"<@\",\"=<@\",\"EST\")),] #exclusion\n",
    "  sum(reasons$N16,na.rm = TRUE)\n",
    "  length(database[,1]) #1375371(-835)\n",
    "  \n",
    "  \n",
    "  # ##################### N19: elimination of records that have \"%\" in qualifier, but not \"%\" in the unit (to be removed), same for \"M\"  ####\n",
    "  temp <- database[(database$UNIT_OF_MEASUREMENT_2!=\"%\" & database$QUALIFIER==\"%\") | (database$UNIT_OF_MEASUREMENT_2!=\"M\" & database$QUALIFIER==\"M\"),]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[(database$UNIT_OF_MEASUREMENT_2!=\"%\" & database$QUALIFIER==\"%\") | (database$UNIT_OF_MEASUREMENT_2!=\"M\" & database$QUALIFIER==\"M\")])\n",
    "  reasons$N19[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!((database$UNIT_OF_MEASUREMENT_2!=\"%\" & database$QUALIFIER==\"%\") | (database$UNIT_OF_MEASUREMENT_2!=\"M\" & database$QUALIFIER==\"M\")),] #exclusion\n",
    "  sum(reasons$N19,na.rm = TRUE)\n",
    "  length(database[,1]) #1375365(-6)\n",
    "  \n",
    "  \n",
    "  #####Removing samples: Unit of measurement is judged erroneous / missing  but the sample result is not null / conflicting with substance\n",
    "  \n",
    "  # ##################### N17 / N18: elimination of records that should not have \"F\" as unit  ####\n",
    "  temp <- database[database$UNIT_OF_MEASUREMENT_2==\"F\",]\n",
    "  class(temp$IMIS_SUBSTANCE_CODE)\n",
    "  temp$IMIS_SUBSTANCE_CODE <- as.character(temp$IMIS_SUBSTANCE_CODE)\n",
    "  table(temp$IMIS_SUBSTANCE_CODE)\n",
    "  #0527  1073  1300  2270  2470  9020  9135  R251 \n",
    "  #   1     5   576     1     1 18105     1   189  \n",
    "  \n",
    "  temp <- database[is.element(database$IMIS_SUBSTANCE_CODE,c('0527','1073','2270','2470','9135')) & database$UNIT_OF_MEASUREMENT_2==\"F\",]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[is.element(database$IMIS_SUBSTANCE_CODE,c('1073','2270','2470','9135')) & database$UNIT_OF_MEASUREMENT_2==\"F\"])\n",
    "  reasons$N1718[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!(is.element(database$IMIS_SUBSTANCE_CODE,c('1073','2270','2470','9135')) & database$UNIT_OF_MEASUREMENT_2==\"F\"),] #exclusion\n",
    "  sum(reasons$N1718,na.rm = TRUE)\n",
    "  length(database[,1]) #1375357(-8)\n",
    "  \n",
    "  \n",
    "  # ##################### N23: elimination of records for which the sample result is not null and that the unit is empty  ####\n",
    "  temp <- database[database$UNIT_OF_MEASUREMENT_2==\"\" & database$SAMPLE_RESULT_2>0,]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[database$UNIT_OF_MEASUREMENT_2==\"\" & database$SAMPLE_RESULT_2>0])\n",
    "  reasons$N23[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!(database$UNIT_OF_MEASUREMENT_2==\"\" & database$SAMPLE_RESULT_2>0),] #exclusion\n",
    "  sum(reasons$N23,na.rm = TRUE)\n",
    "  length(database[,1]) #1374125(-1232)\n",
    "  \n",
    "  \n",
    "  # ##################### N24: elimination of cases where unit is \"%\" in unit, but sample_result is >100  ####\n",
    "  temp <- database[database$UNIT_OF_MEASUREMENT_2==\"%\" & database$SAMPLE_RESULT_2>100,]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[database$UNIT_OF_MEASUREMENT_2==\"%\" & database$SAMPLE_RESULT_2>100])\n",
    "  reasons$N24[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!(database$UNIT_OF_MEASUREMENT_2==\"%\" & database$SAMPLE_RESULT_2>100),] #exclusion\n",
    "  sum(reasons$N24,na.rm = TRUE)\n",
    "  length(database[,1]) #1374117(-8)\n",
    "  \n",
    "  \n",
    "  ## Modification of variables qualifier and air volume sampled ####\n",
    "  ##creating a qualifier.2 : detected / not detected\n",
    "  database$QUALIFIER_2 <- rep('detected',length(database[,1]))\n",
    "  database$QUALIFIER_2[database$SAMPLE_RESULT_2==0] <- 'ND'\t\n",
    "  \n",
    "  ##standardizing air volume sampled\n",
    "  #sampvol.conv <-read.table(\"sampvol.conv.new.csv\", header=T, sep=\",\", stringsAsFactor=F)\n",
    "  #sampvol.conv.1 <-read.table(\"sampvol.conv.1.new.csv\", header=T, sep=\",\", stringsAsFactor=F)\n",
    "  #sampvol.conv.rest <-read.table(\"sampvol.conv.rest.new.csv\", header=T, sep=\",\", stringsAsFactor=F)\n",
    "  #sampvol.conv.rest.1 <-read.table(\"sampvol.conv.rest.1.new.csv\", header=T, sep=\",\", stringsAsFactor=F)\n",
    "  #sampvol.conv.tot <-rbind(sampvol.conv,sampvol.conv.rest,sampvol.conv.1,sampvol.conv.rest.1)\n",
    "  #write_xlsx(x = sampvol.conv.tot, path = \"sampvol.conv.tot.xlsx\", col_names = TRUE)\n",
    "  \n",
    "  #**** this step is simplified for the 2020 cleanup: AIR_VOLUME_SAMPLED==NA, 0 or empty are deleted at N22 / N27 **** \n",
    "  class(database$AIR_VOLUME_SAMPLED)\n",
    "  length(database$AIR_VOLUME_SAMPLED[is.na(database$AIR_VOLUME_SAMPLED)]) #[1] 3897\n",
    "  temp <- database[which(is.na(as.numeric(as.character(database$AIR_VOLUME_SAMPLED)))),]\n",
    "  summary(database$AIR_VOLUME_SAMPLED,na.rm=TRUE)\n",
    "  #   Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n",
    "  #   0.0     30.8    314.4    368.9    606.0 924560.0     3897 \n",
    "  cehd_top <- database[1:5000,]\n",
    "  \n",
    "  \n",
    "  #further standardization of units\n",
    "  #based on the units for the personal cleaned, we keep only the %, F, M, P data\n",
    "  #in addition sample weight must not be null for detected results with perc\n",
    "  \n",
    "  #list of 29 substances with most records\n",
    "  subst <- data.frame(table(database$IMIS_SUBSTANCE_CODE))\n",
    "  names(subst) <-c('code','n')\n",
    "  subst <- subst[order(-subst$n),]\n",
    "  nrow(subst) #[1] 257\n",
    "  list_29 <- as.character(sort(subst$code[c(1:29)]))\n",
    "  list_29\n",
    "  \n",
    "  #list used in 2011 cleanup\n",
    "  substances.list.29 <-c('0040','0230','0260','0360','0430','0491','0685','0720','0731','1073','1290','1520','1560',\n",
    "                         '1591','1620','1730','1790','1840','2270','2280','2460','2571','2590','2610','9020','9130','9135','C141','S103')\n",
    "  \n",
    "  setdiff(list_29,substances.list.29) #[1] \"9010\"\n",
    "  setdiff(substances.list.29,list_29) #[1] \"S103\"\n",
    "  #9010 is replaced by S103 in the list\n",
    "  sum(subst$n[is.element(subst$code,substances.list.29)]) #[1] 1099503\n",
    "  \n",
    "  #list used in 2011 cleanup will also be used in the current 2020 cleanup\n",
    "  \n",
    "  # ##################### N31: record from the '29' (with 9010 excluded) and unit is not part of '','F','P','M'  ####\n",
    "  #table(database$UNIT_OF_MEASUREMENT_2)\n",
    "  temp <- database[(is.element(database$IMIS_SUBSTANCE_CODE,substances.list.29)) &\n",
    "                    (!is.element(database$UNIT_OF_MEASUREMENT_2,c('','F','P','M'))),]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[(is.element(database$IMIS_SUBSTANCE_CODE,substances.list.29)) &\n",
    "                                   (!is.element(database$UNIT_OF_MEASUREMENT_2,c('','F','P','M')))])\n",
    "  reasons$N31[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!((is.element(database$IMIS_SUBSTANCE_CODE,substances.list.29)) &\n",
    "                         (!is.element(database$UNIT_OF_MEASUREMENT_2,c('','F','P','M')))),] #exclusion\n",
    "  sum(reasons$N31,na.rm = TRUE)\n",
    "  length(database[,1]) #1371807(-2310)\n",
    "  #temp <- database[database$UNIT_OF_MEASUREMENT_2==\"%\",]\n",
    "  \n",
    "  \n",
    "  # ##################### N32: record from substance '9010' : if not '','%' or 'M' eliminate  ####\n",
    "  table(database$UNIT_OF_MEASUREMENT_2)\n",
    "   \n",
    "  temp <- database[(is.element(database$IMIS_SUBSTANCE_CODE,'9010')) &\n",
    "                     (!is.element(database$UNIT_OF_MEASUREMENT_2,c('','%','M'))),]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[(is.element(database$IMIS_SUBSTANCE_CODE,'9010')) &\n",
    "                                   (!is.element(database$UNIT_OF_MEASUREMENT_2,c('','%','M')))])\n",
    "  reasons$N32[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!((is.element(database$IMIS_SUBSTANCE_CODE,'9010')) &\n",
    "                           (!is.element(database$UNIT_OF_MEASUREMENT_2,c('','%','M')))),] #exclusion\n",
    "  sum(reasons$N32,na.rm = TRUE)\n",
    "  length(database[,1]) #1371631(-176)\n",
    "  #temp <- database[database$UNIT_OF_MEASUREMENT_2==\"%\",]\n",
    "  \n",
    "  \n",
    "  # ##################### N33: record not from 29 substances or  '9010' : if not '','P','F','%' or 'M' eliminate  ####\n",
    "  #table(database$UNIT_OF_MEASUREMENT_2)\n",
    "  restrict <- !database$IMIS_SUBSTANCE_CODE=='9010' & !is.element(database$IMIS_SUBSTANCE_CODE,substances.list.29)\n",
    "  temp <- database[restrict & (!is.element(database$UNIT_OF_MEASUREMENT_2,c('','%','M','P','F'))),]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[restrict & (!is.element(database$UNIT_OF_MEASUREMENT_2,c('','%','M','P','F')))])\n",
    "  reasons$N33[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!(restrict & (!is.element(database$UNIT_OF_MEASUREMENT_2,c('','%','M','P','F')))),] #exclusion\n",
    "  sum(reasons$N33,na.rm = TRUE)\n",
    "  length(database[,1]) #1369269(-2362)\n",
    "  #temp <- database[database$UNIT_OF_MEASUREMENT_2==\"%\",]\n",
    "\n",
    "  \n",
    "  # ##################### N34: elimination when unit is perc (%) and the result is non null but sample weight is null ####\n",
    "  #missing sampling weight replaced by 0\n",
    "  database$SAMPLE_WEIGHT_2 <- database$SAMPLE_WEIGHT\n",
    "  length(database$SAMPLE_WEIGHT_2[is.na(database$SAMPLE_WEIGHT)])\n",
    "  database$SAMPLE_WEIGHT_2[is.na(database$SAMPLE_WEIGHT)] <- 0\n",
    "  length(database$SAMPLE_WEIGHT_2[is.na(database$SAMPLE_WEIGHT_2)])\n",
    "  \n",
    "  temp <- database[database$SAMPLE_WEIGHT_2==0 & database$UNIT_OF_MEASUREMENT_2==\"%\" & \n",
    "                   database$SAMPLE_RESULT_2>0,]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[database$SAMPLE_WEIGHT_2==0 & database$UNIT_OF_MEASUREMENT_2==\"%\" & \n",
    "                                   database$SAMPLE_RESULT_2>0])\n",
    "  reasons$N34[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!(database$SAMPLE_WEIGHT_2==0 & database$UNIT_OF_MEASUREMENT_2==\"%\" & \n",
    "                           database$SAMPLE_RESULT_2>0),] #exclusion\n",
    "  sum(reasons$N34,na.rm = TRUE)\n",
    "  length(database[,1]) #1366423(-2846)\n",
    "  \n",
    "  #transformation of percs into mg/m3\t\t\t\t\t\t\t\t\t\t\n",
    "  length(database$SAMPLE_WEIGHT_2[is.na(database$SAMPLE_WEIGHT_2)]) #[1] 0\n",
    "  length(database$AIR_VOLUME_SAMPLED[is.na(database$AIR_VOLUME_SAMPLED)]) #[1] 3309\n",
    "  table(database$UNIT_OF_MEASUREMENT_2)\n",
    "  #            %       F       M       P \n",
    "  #28136   32483   18871 1019691  267242\n",
    "  \n",
    "  restrict.1 <- database$SAMPLE_WEIGHT_2!=0 &\n",
    "    database$UNIT_OF_MEASUREMENT_2=='%' &\n",
    "    database$SAMPLE_RESULT_2>0 &\n",
    "    !is.na(database$SAMPLE_WEIGHT_2) &\n",
    "    !is.na(database$AIR_VOLUME_SAMPLED) & database$AIR_VOLUME_SAMPLED>0\n",
    "  \n",
    "  database$SAMPLE_RESULT_3 <- database$SAMPLE_RESULT_2\n",
    "  \n",
    "  database$SAMPLE_RESULT_3[restrict.1] <- database$SAMPLE_RESULT_2[restrict.1]*\n",
    "    database$SAMPLE_WEIGHT_2[restrict.1]*10/\n",
    "    database$AIR_VOLUME_SAMPLED[restrict.1]\t\t\t\t\t\t\t\t\t\t\n",
    "  \n",
    "  database$UNIT_OF_MEASUREMENT_2[restrict.1] <- 'M.from.Perc'\n",
    "  temp <- database[database$UNIT_OF_MEASUREMENT_2==\"P\",]\n",
    "  \n",
    "  table(database$UNIT_OF_MEASUREMENT_2)\n",
    "  #                %           F           M M.from.Perc           P \n",
    "  #28136       16779       18871     1019691       15704      26724 \n",
    "  \n",
    "  \n",
    "  # ##################### N20: elimination of the records that have a missing value for the office ID  ####\n",
    "  temp <- database[is.na(database$OFFICE_ID),]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[is.na(database$OFFICE_ID)])\n",
    "  reasons$N20[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!is.na(database$OFFICE_ID),] #exclusion\n",
    "  sum(reasons$N20,na.rm = TRUE)\n",
    "  length(database[,1]) #1363807(-2616)\n",
    "  \n",
    "  \n",
    "  # ##################### N21: records that have a missing time_sampled variable are deleted  ####\n",
    "  temp <- database[is.na(database$TIME_SAMPLED),]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[is.na(database$TIME_SAMPLED)])\n",
    "  reasons$N21[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!is.na(database$TIME_SAMPLED),] #exclusion\n",
    "  sum(reasons$N21,na.rm = TRUE)\n",
    "  length(database[,1]) #1362164(-1643)\n",
    "  \n",
    "  \n",
    "  # ##################### N26: elimination of the records that have a null time_sampled variable   ####\n",
    "  temp <- database[database$TIME_SAMPLED==0,]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[database$TIME_SAMPLED==0])\n",
    "  reasons$N26[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[database$TIME_SAMPLED!=0,] #exclusion\n",
    "  sum(reasons$N26,na.rm = TRUE)\n",
    "  length(database[,1]) #1357348(-4816)\n",
    "  \n",
    "  \n",
    "  # ##################### N28: elimination of sample results less than 0   ####\n",
    "  temp <- database[database$SAMPLE_RESULT_3<0,]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[database$SAMPLE_RESULT_3<0])\n",
    "  reasons$N28[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[database$SAMPLE_RESULT_3>=0,] #exclusion\n",
    "  sum(reasons$N28,na.rm = TRUE)\n",
    "  length(database[,1]) #1357347(-1)\n",
    "  \n",
    "  \n",
    "  # ##################### N25: records to be deleted because of a missing or null sampling number   ####\n",
    "  temp <- database[is.na(database$SAMPLING_NUMBER) | database$SAMPLING_NUMBER==0,]\n",
    "   \n",
    "  vec_eff <- table(database$YEAR[is.na(database$SAMPLING_NUMBER) | database$SAMPLING_NUMBER==0])\n",
    "  reasons$N25[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!(is.na(database$SAMPLING_NUMBER) | database$SAMPLING_NUMBER==0),] #exclusion\n",
    "  sum(reasons$N25,na.rm = TRUE)\n",
    "  length(database[,1]) #1355916(-1431)\n",
    "  \n",
    "  \n",
    "  # ##################### N22: records that have a NA or '' volume sampled variable are deleted   ####\n",
    "  summary(database$AIR_VOLUME_SAMPLED)\n",
    "  #  Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     NA's \n",
    "  #   0.0     32.1    316.6    370.3    608.9 924560.0     1705 \n",
    "  temp <- database[is.na(database$AIR_VOLUME_SAMPLED),] #1705\n",
    "  temp <- database[is.na(database$AIR_VOLUME_SAMPLED) | database$AIR_VOLUME_SAMPLED=='',] #1705\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[is.na(database$AIR_VOLUME_SAMPLED) | database$AIR_VOLUME_SAMPLED==''])\n",
    "  reasons$N22[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!(is.na(database$AIR_VOLUME_SAMPLED) | database$AIR_VOLUME_SAMPLED==''),] #exclusion\n",
    "  sum(reasons$N22,na.rm = TRUE)\n",
    "  length(database[,1]) #1354211(-1705)\n",
    "  \n",
    "  \n",
    "  # ##################### N27: elimination of records that have an air volume sampled of zero   ####\n",
    "  summary(database$AIR_VOLUME_SAMPLED)\n",
    "  #  Min.  1st Qu.   Median     Mean  3rd Qu.     Max.     \n",
    "  #   0.0     32.1    316.6    370.3    608.9 924560.0     \n",
    "  temp <- database[database$AIR_VOLUME_SAMPLED==0,] \n",
    "  \n",
    "  vec_eff <- table(database$YEAR[database$AIR_VOLUME_SAMPLED==0])\n",
    "  reasons$N27[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[database$AIR_VOLUME_SAMPLED>0,] #exclusion\n",
    "  sum(reasons$N27,na.rm = TRUE)\n",
    "  length(database[,1]) #1341727(-12484)\n",
    "  \n",
    "  \n",
    "  # ##################### N35: instrument type is equal to ''   ####\n",
    "  #temp <- database[database$INSTRUMENT_TYPE=='' & !is.na(database$INSTRUMENT_TYPE),] \n",
    "  #temp <- database[is.na(database$INSTRUMENT_TYPE),] \n",
    "  #table(temp$YEAR)\n",
    "  \n",
    "  restrictN35 <- database$INSTRUMENT_TYPE=='' & !is.na(database$INSTRUMENT_TYPE)\n",
    "  #table(restrictN35)\n",
    "  \n",
    "  temp <- database[restrictN35,]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[restrictN35])\n",
    "  reasons$N35[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!restrictN35,] #exclusion\n",
    "  sum(reasons$N35,na.rm = TRUE)\n",
    "  length(database[,1]) #1341727(-0)\n",
    "  \n",
    "  \n",
    "  # ##################### N37: instrument type is missing   ####\n",
    "  #****NAs are not removed at this step: they are treated at N36**** \n",
    "  temp <- database[is.na(database$INSTRUMENT_TYPE),] \n",
    "  table(temp$YEAR)\n",
    "  restrictN37 <- is.na(database$INSTRUMENT_TYPE)\n",
    "  table(restrictN37)\n",
    "  #  FALSE    TRUE \n",
    "  #1171397  170330 \n",
    "   \n",
    "  \n",
    "  # ##################### N36: cleaning of instrument type ####\n",
    "  database$INSTRUMENT_TYPE[is.na(database$INSTRUMENT_TYPE)] <- ''\n",
    "  length(database$INSTRUMENT_TYPE[database$INSTRUMENT_TYPE=='']) #[1] 170330\n",
    "  temp <- database[database$INSTRUMENT_TYPE=='',]\n",
    "  \n",
    "  ### cleaning strategy ###\n",
    "  #original 81 substances: clean for 1984-2009 using IT tables\n",
    "  #original 81 substances: copy raw IT for 2010-2011\n",
    "  #new substances: copy raw IT for 1984-2011\n",
    "  #all substances: indicate \"not recorded\" for 2013-2018\n",
    "\n",
    "  #1) all substances: create INSTRUMENT_TYPE_2 variable + indicate \"not recorded\" for all years (1984-2018)\n",
    "  database$INSTRUMENT_TYPE_2 <- 'not recorded'\n",
    "  \n",
    "  #2) all substances: copy raw IT for 1984-2011\n",
    "  database$INSTRUMENT_TYPE_2[as.numeric(as.character(database$YEAR))<2012] <- database$INSTRUMENT_TYPE[as.numeric(as.character(database$YEAR))<2012]\n",
    "  temp <- database[database$INSTRUMENT_TYPE_2=='not recorded',]\n",
    "  table(temp$YEAR)\n",
    "  \n",
    "  #3) original 81 substances: clean for 1984-2009 using IT tables\n",
    "  #store tables in a list object\n",
    "  setwd('C:\\\\Users\\\\phisar\\\\Dropbox (IRSST)\\\\PhD\\\\Projet IMIS\\\\Rï¿½sultats\\\\IMIS_ND_predict\\\\CEHD 84_18\\\\Conversion tables IT')\n",
    "  files <- list.files()\n",
    "  n <- length(files)\n",
    "  data.list <- vector(mode=\"list\",n)\n",
    "  \n",
    "  for (i in 1:n) {\n",
    "    subs_code <- substr(files[i],3,6)\n",
    "    data.list[[i]] <- read.csv(files[i],sep=\",\", header=TRUE)\n",
    "    names(data.list)[i] <- subs_code\n",
    "    print(i)\n",
    "  }\n",
    "  \n",
    "  data.list[i]\n",
    "  \n",
    "  length(database$IMIS_SUBSTANCE_CODE[database$IMIS_SUBSTANCE_CODE==\"0040\"])\n",
    "  #[1] 10726\n",
    "  length(database$IMIS_SUBSTANCE_CODE[database$IMIS_SUBSTANCE_CODE==\"0040\" & as.numeric(as.character(database$YEAR))<2010])\n",
    "  #[1] 9691\n",
    "  \n",
    "  for (i in 1:n) {\n",
    "    \n",
    "    restrict <- database$IMIS_SUBSTANCE_CODE==names(data.list)[i] & as.numeric(as.character(database$YEAR))<2010\n",
    "    table(restrict)\n",
    "    \n",
    "    unik.clean <- unique(data.list[[i]]$clean)\n",
    "    \n",
    "    for (j in 1:length(unik.clean))\n",
    "    {\n",
    "      one.clean <- as.character(unik.clean)[j]\n",
    "      raw.values <- as.character(data.list[[i]]$raw[data.list[[i]]$clean==one.clean])\n",
    "      \n",
    "      database$INSTRUMENT_TYPE_2[restrict & is.element(database$INSTRUMENT_TYPE,raw.values)] <- one.clean\n",
    "     }\n",
    "    \n",
    "    print(i)\n",
    "    }\n",
    "  \n",
    "  #verifications\n",
    "  #View(database[,c(9,11,22,26,32,33)])\n",
    "  #View(database[database$INSTRUMENT_TYPE=='',c(9,11,22,26,32,33)])\n",
    "  #View(database[database$INSTRUMENT_TYPE_2=='',c(9,11,22,26,32,33)])\n",
    "  \n",
    "  temp <- database[database$INSTRUMENT_TYPE_2=='',]\n",
    "  table(temp$YEAR)\n",
    "  \n",
    "  temp <- database[database$IMIS_SUBSTANCE_CODE==\"9135\",c(9,11,26,32,33)]\n",
    "  temp <- database[database$IMIS_SUBSTANCE_CODE==\"9135\" & database$INSTRUMENT_TYPE=='',c(9,11,26,32,33)]\n",
    "  table(temp$YEAR)\n",
    "  \n",
    "  #4) replace INSTRUMENT_TYPE_2=='' by INSTRUMENT_TYPE_2=='eliminate' (these records correspond to \n",
    "  #   new substances <2012 which didn't have an IT recorded)\n",
    "  length(database$INSTRUMENT_TYPE_2[database$INSTRUMENT_TYPE_2=='']) #[1] 129\n",
    "  database$INSTRUMENT_TYPE_2[database$INSTRUMENT_TYPE_2==''] <- 'eliminate'\n",
    "  \n",
    "  \n",
    "  #exclusion\n",
    "  restrictN36 <- database$INSTRUMENT_TYPE_2=='eliminate'\n",
    "  table(restrictN36)\n",
    "  #  FALSE    TRUE \n",
    "  #1330338   11389\n",
    "  \n",
    "  temp <- database[restrictN36,]\n",
    "  \n",
    "  vec_eff <- table(database$YEAR[restrictN36])\n",
    "  reasons$N36[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database <- database[!restrictN36,] #exclusion\n",
    "  sum(reasons$N36,na.rm = TRUE)\n",
    "  length(database[,1]) #1330338(-11389)\n",
    "  \n",
    "  \n",
    "  # ##################### Duplicates ####\n",
    "  names(database)\n",
    "  #creating the hash variable\n",
    "  database$HASH <- paste(database$INSPECTION_NUMBER,\n",
    "                         database$IMIS_SUBSTANCE_CODE,\n",
    "                         database$SAMPLING_NUMBER,\n",
    "                         database$FIELD_NUMBER,sep='-')\n",
    "  \n",
    "  #file listing the problematic hash codes\t\t\t\t\t\n",
    "  bla <- data.frame(table(database$HASH),stringsAsFactors=F)\n",
    "  names(bla) <- c('name','n')\n",
    "  bla <- bla[bla$n>1,]\n",
    "  bla$name <- as.character(bla$name)\n",
    "  bla$code <- database$IMIS_SUBSTANCE_CODE[match(bla$name,database$HASH)]\n",
    "  bla$sub <- database$SUBSTANCE[match(bla$name,database$HASH)]\n",
    "  length(bla$name) #[1] 6587\n",
    "  sum(bla$n) #[1] 13197\n",
    "  \n",
    "  #creating a concatenated variable to identify if there are true duplicates\n",
    "  database$CONCAT <- paste(database$LAB_NUMBER,\n",
    "                           database$STATE,\n",
    "                           database$ZIP_CODE,\n",
    "                           database$YEAR,\n",
    "                           database$TIME_SAMPLED,\n",
    "                           database$SAMPLE_WEIGHT_2,\n",
    "                           sep='-')\n",
    "  \n",
    "  \n",
    "  #identification of cases where \"CONCAT\" is the same \n",
    "  bla$concatdiff <- rep(F,length(bla[,1]))\n",
    "  \n",
    "  for (i in 1:length(bla[,1])) {\n",
    "  \n",
    "    if (length(unique(database$CONCAT[database$HASH==bla$name[i]]))!=1) bla$concatdiff[i] <- T \n",
    "    print(i)\n",
    "    \n",
    "    }\n",
    "  \n",
    "  table(bla$concatdiff)\n",
    "  \n",
    "  bla$name\n",
    "  bla$name[1]\n",
    "  temp <- database[database$HASH==\"100014786-9010-1179480-HLR1\",]\n",
    "  \n",
    "  saveRDS(bla, file=\"C:\\\\Users\\\\phisar\\\\Dropbox (IRSST)\\\\PhD\\\\Projet IMIS\\\\Rï¿½sultats\\\\IMIS_ND_predict\\\\CEHD 84_18\\\\bla.Rda\")\n",
    "  bla <- readRDS(file=\"C:\\\\Users\\\\phisar\\\\Dropbox (IRSST)\\\\PhD\\\\Projet IMIS\\\\Rï¿½sultats\\\\IMIS_ND_predict\\\\CEHD 84_18\\\\bla.Rda\")\n",
    "  table(bla$concatdiff)\n",
    "  #FALSE  TRUE \n",
    "  # 3136  3451 \n",
    "  sum(bla$n) #[1] 13197\n",
    "  sum(bla$n[bla$concatdiff==FALSE]) #[1] 6272\n",
    "  sum(bla$n[bla$concatdiff==TRUE]) #[1] 6925\n",
    "    \n",
    "  #### M: false duplicates ####\n",
    "  #list of hash codes to eliminate because \"CONCAT\" variable varies\n",
    "  Hash.list.diff.concat <- bla$name[bla$concatdiff==TRUE]\n",
    "  \n",
    "  #elimination of these\n",
    "  restrictM <- is.element(database$HASH,Hash.list.diff.concat)\n",
    "  \n",
    "  temp <- database[restrictM,] \n",
    "  \n",
    "  vec_eff <- table(database$YEAR[restrictM])\n",
    "  reasons$M[match(names(vec_eff), reasons$YEAR)] <- vec_eff\n",
    "  \n",
    "  database.1 <- database[!restrictM,] #exclusion\n",
    "  sum(reasons$M,na.rm = TRUE)\n",
    "  length(database.1[,1]) #1323413(-6925)\n",
    "  \n",
    "  \n",
    "  #### N: true duplicates ####\n",
    "  ##treatment of cases with equal \"CONCAT\" variable values\n",
    "  \n",
    "  #we separate the DB into the OK and remaining problematic\n",
    "  \n",
    "  database.1.ok <- database.1[!is.element(database.1$HASH,bla$name),]\n",
    "  length(database.1.ok[,1]) #[1] 1317141\n",
    "  database.1.nonok <- database.1[is.element(database.1$HASH,bla$name),]\n",
    "  length(database.1.nonok[,1]) #[1] 6272\n",
    "  \n",
    "  # treating the OK\n",
    "  bla.diff <- bla[bla$concatdiff==FALSE,]\n",
    "  table(bla.diff$n>2)\n",
    "  table(database$UNIT_OF_MEASUREMENT_2[is.element(database$HASH,bla.diff$name)])\n",
    "  table(database$IMIS_SUBSTANCE_CODE[is.element(database$HASH,bla.diff$name)])\n",
    "  #0040 0430 0520 0685 0720 0731 1591 1631 1720 1790 2460 2590 9010 9015 9020 C141 S103 T177 \n",
    "  #   2    2   14    2    2    2   24   10    2    2    6   22 6084   50   30   12    4    2\n",
    "  true.duplicates <- database[is.element(database$HASH,bla.diff$name),]\n",
    "  \n",
    "  # majority is 9010 (e.g. duplicates of \"M\" and \"M.from.Perc\" cases) \n",
    "  # only 9010 treated, remaining cases are deleted\n",
    "  database.1.nonok.9010 <- database.1.nonok[database.1.nonok$IMIS_SUBSTANCE_CODE==\"9010\",]\n",
    "  length(database.1.nonok.9010[,1]) #[1]  6084\n",
    "  table(database.1.nonok.9010$UNIT_OF_MEASUREMENT_2)\n",
    "  #              %           M M.from.Perc \n",
    "  #437        1177        2822        1648 \n",
    "  temp <- database.1.nonok.9010[database.1.nonok.9010$UNIT_OF_MEASUREMENT_2=='M.from.Perc',]\n",
    "  #data are sorted according to HASH and one out of 2 records is retained\n",
    "  database.1.nonok.9010 <- database.1.nonok.9010[order(database.1.nonok.9010$HASH),]\n",
    "  database.1.nonok.9010 <- database.1.nonok.9010[seq(from=1,to=6083,by=2),]\n",
    "  length(database.1.nonok.9010[,1]) #[1]  3042\n",
    "  \n",
    "  # binding of two subsets of database.1\n",
    "  database.final <- rbind(database.1.ok,database.1.nonok.9010)\n",
    "  nrow(database.1) - nrow(database.final)\n",
    "  length(database.final[,1]) #[1] 1320183 (-3230)\n",
    "  \n",
    "  \n",
    "  #### finalizing database ####\n",
    "  #finalizing variable class\n",
    "  str(database.final)\n",
    "  \n",
    "  database.final$LAB_NUMBER <- as.character(database.final$LAB_NUMBER)\n",
    "  database.final$OFFICE_ID <- as.character(database.final$OFFICE_ID)\n",
    "  database.final$SIC_CODE <- as.character(database.final$SIC_CODE)\n",
    "  database.final$STATE <- as.character(database.final$STATE)\n",
    "  database.final$ZIP_CODE <- as.character(database.final$ZIP_CODE)\n",
    "  \n",
    "  saveRDS(database.final, file=\"C:\\\\Users\\\\phisar\\\\Dropbox (IRSST)\\\\PhD\\\\Projet IMIS\\\\Rï¿½sultats\\\\IMIS_ND_predict\\\\CEHD 84_18\\\\CEHD_84_18_clean_allfields.rds\")\n",
    "  \n",
    "  #final variable names\n",
    "  #CEHD <- read.csv(\"C:\\\\Users\\\\phisar\\\\Documents\\\\Data_CEHD\\\\CEHD.csv\",sep=\",\", header=T)\n",
    "  #dim(CEHD) #[1] 1037395      23\n",
    "  #names(CEHD)\n",
    "  #[1] \"inspection_number\"     \"establishment_name\"    \"city\"                  \"state\"                 \"zip_code\"             \n",
    "  #[6] \"sic_code\"              \"naics_code\"            \"sampling_number\"       \"office_id\"             \"date_sampled\"         \n",
    "  #[11] \"date_reported\"         \"field_number\"          \"time_sampled\"          \"imis_substance_code\"   \"substance\"            \n",
    "  #[16] \"unit_of_measurement_N\" \"sample_weight_N\"       \"air_volume_sampled_N\"  \"sample_result_N\"       \"instrument_type_N\"    \n",
    "  #[21] \"hash\"                  \"data_source\"           \"position_in_source\"   \n",
    "  \n",
    "  names(database.final)\n",
    "  #[1] \"AIR_VOLUME_SAMPLED\"    \"BLANK_USED\"            \"CITY\"                  \"DATE_REPORTED\"         \"DATE_SAMPLED\"         \n",
    "  #[6] \"EIGHT_HOUR_TWA_CALC\"   \"ESTABLISHMENT_NAME\"    \"FIELD_NUMBER\"          \"IMIS_SUBSTANCE_CODE\"   \"INSPECTION_NUMBER\"    \n",
    "  #[11] \"INSTRUMENT_TYPE\"       \"LAB_NUMBER\"            \"NAICS_CODE\"            \"OFFICE_ID\"             \"QUALIFIER\"            \n",
    "  #[16] \"SAMPLE_RESULT\"         \"SAMPLE_TYPE\"           \"SAMPLE_WEIGHT\"         \"SAMPLING_NUMBER\"       \"SIC_CODE\"             \n",
    "  #[21] \"STATE\"                 \"SUBSTANCE\"             \"TIME_SAMPLED\"          \"UNIT_OF_MEASUREMENT\"   \"ZIP_CODE\"             \n",
    "  #[26] \"YEAR\"                  \"CENSORED\"              \"SAMPLE_RESULT_2\"       \"UNIT_OF_MEASUREMENT_2\" \"QUALIFIER_2\"          \n",
    "  #[31] \"SAMPLE_WEIGHT_2\"       \"SAMPLE_RESULT_3\"       \"INSTRUMENT_TYPE_2\"     \"HASH\"                  \"CONCAT\"    \n",
    "  \n",
    "  names(database.final)[1] <-'air_volume_sampled_N'\n",
    "  names(database.final)[3] <-'city'\n",
    "  names(database.final)[4] <-'date_reported'\n",
    "  names(database.final)[5] <-'date_sampled'\n",
    "  names(database.final)[7] <-'establishment_name'\n",
    "  names(database.final)[8] <-'field_number'\n",
    "  names(database.final)[9] <-'imis_substance_code'\n",
    "  names(database.final)[10] <-'inspection_number'\n",
    "  names(database.final)[12] <-'lab_number'\n",
    "  names(database.final)[13] <-'naics_code'\n",
    "  names(database.final)[14] <-'office_id'\n",
    "  names(database.final)[19] <-'sampling_number'\n",
    "  names(database.final)[20] <-'sic_code'\n",
    "  names(database.final)[21] <-'state'\n",
    "  names(database.final)[22] <-'substance'\n",
    "  names(database.final)[23] <-'time_sampled'\n",
    "  names(database.final)[25] <-'zip_code'\n",
    "  names(database.final)[26] <-'year'\n",
    "  names(database.final)[29] <-'unit_of_measurement_N'\n",
    "  names(database.final)[31] <-'sample_weight_N'\n",
    "  names(database.final)[32] <-'sample_result_N'\n",
    "  names(database.final)[33] <-'instrument_type_N'\n",
    "  names(database.final)[34] <-'hash'\n",
    "  \n",
    "  # selection and ordering of final variables\n",
    "  database.final.1 <- database.final[,-c(2,6,11,15,16,17,18,24,27,28,30,35),drop=FALSE]\n",
    "  names(database.final.1)\n",
    "  #[1] \"air_volume_sampled_N\"  \"city\"                  \"date_reported\"         \"date_sampled\"          \"establishment_name\"   \n",
    "  #[6] \"field_number\"          \"imis_substance_code\"   \"inspection_number\"     \"lab_number\"            \"naics_code\"           \n",
    "  #[11] \"office_id\"             \"sampling_number\"       \"sic_code\"              \"state\"                 \"substance\"            \n",
    "  #[16] \"time_sampled\"          \"zip_code\"              \"year\"                  \"unit_of_measurement_N\" \"sample_weight_N\"      \n",
    "  #[21] \"sample_result_N\"       \"instrument_type_N\"     \"hash\"  \n",
    "  database.final.2 <- database.final.1[,c(8,5,2,14,17,13,10,12,11,9,4,3,6,18,7,15,22,20,16,1,21,19,23)]\n",
    "  dim(database.final.2)\n",
    "  # [1] 1320183      23\n",
    "  \n",
    "  subst <- data.frame(table(database.final.2$imis_substance_code))\n",
    "  names(subst) <-c('code','n')\n",
    "  subst <- subst[order(-subst$n),]\n",
    "  nrow(subst) #[1] 257\n",
    "  \n",
    "  length(unique(database.final.2$hash))\n",
    "  \n",
    "  saveRDS(database.final.2, file=\"C:\\\\Users\\\\phisar\\\\Dropbox (IRSST)\\\\PhD\\\\Projet IMIS\\\\Rï¿½sultats\\\\IMIS_ND_predict\\\\CEHD 84_18\\\\CEHD_84_18_clean.rds\")\n",
    "  \n",
    "  cehd <- readRDS(\"C:\\\\Users\\\\phisar\\\\Dropbox (IRSST)\\\\PhD\\\\Projet IMIS\\\\Rï¿½sultats\\\\IMIS_ND_predict\\\\CEHD 84_18\\\\CEHD_84_18_clean.rds\")\n",
    "  dim(cehd) #[1] 2395071      26\n",
    "  # [1] 1320183      23\n",
    "  \n",
    "  length(cehd$instrument_type_N[cehd$instrument_type_N==\"raw was NA\"])\n",
    "  \n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
